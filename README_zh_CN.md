<div align="center">
<img src="./assets/xorbits-logo.png" width="180px" alt="xorbits" />

# Xorbits Inferenceï¼šæ¨¡å‹æ¨ç†ï¼Œ è½»è€Œæ˜“ä¸¾ ğŸ¤–

[![PyPI Latest Release](https://img.shields.io/pypi/v/xinference.svg?style=for-the-badge)](https://pypi.org/project/xinference/)
[![License](https://img.shields.io/pypi/l/xinference.svg?style=for-the-badge)](https://github.com/xorbitsai/inference/blob/main/LICENSE)
[![Build Status](https://img.shields.io/github/actions/workflow/status/xorbitsai/inference/python.yaml?branch=main&style=for-the-badge&label=GITHUB%20ACTIONS&logo=github)](https://actions-badge.atrox.dev/xorbitsai/inference/goto?ref=main)
[![Slack](https://img.shields.io/badge/join_Slack-781FF5.svg?logo=slack&style=for-the-badge)](https://join.slack.com/t/xorbitsio/shared_invite/zt-1o3z9ucdh-RbfhbPVpx7prOVdM1CAuxg)
[![Twitter](https://img.shields.io/twitter/follow/xorbitsio?logo=twitter&style=for-the-badge)](https://twitter.com/xorbitsio)

[English](README.md) | ä¸­æ–‡ä»‹ç» | [æ—¥æœ¬èª](README_ja_JP.md)
</div>
<br />


Xorbits Inferenceï¼ˆXinferenceï¼‰æ˜¯ä¸€ä¸ªæ€§èƒ½å¼ºå¤§ä¸”åŠŸèƒ½å…¨é¢çš„åˆ†å¸ƒå¼æ¨ç†æ¡†æ¶ã€‚å¯ç”¨äºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œè¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œå¤šæ¨¡æ€æ¨¡å‹ç­‰å„ç§æ¨¡å‹çš„æ¨ç†ã€‚é€šè¿‡ Xorbits Inferenceï¼Œä½ å¯ä»¥è½»æ¾åœ°ä¸€é”®éƒ¨ç½²ä½ è‡ªå·±çš„æ¨¡å‹æˆ–å†…ç½®çš„å‰æ²¿å¼€æºæ¨¡å‹ã€‚æ— è®ºä½ æ˜¯ç ”ç©¶è€…ï¼Œå¼€å‘è€…ï¼Œæˆ–æ˜¯æ•°æ®ç§‘å­¦å®¶ï¼Œéƒ½å¯ä»¥é€šè¿‡ Xorbits Inference ä¸æœ€å‰æ²¿çš„ AI æ¨¡å‹ï¼Œå‘æ˜æ›´å¤šå¯èƒ½ã€‚


<div align="center">
<i><a href="https://join.slack.com/t/xorbitsio/shared_invite/zt-1z3zsm9ep-87yI9YZ_B79HLB2ccTq4WA">ğŸ‘‰ ç«‹åˆ»åŠ å…¥æˆ‘ä»¬çš„ Slack ç¤¾åŒº!</a></i>
</div>

## ğŸ”¥ è¿‘æœŸçƒ­ç‚¹
### æ¡†æ¶å¢å¼º
- è‡ªå®šä¹‰æ¨¡å‹: [#325](https://github.com/xorbitsai/inference/pull/325)
- LoRA æ”¯æŒ: [#271](https://github.com/xorbitsai/inference/issues/271)
- PyTorch æ¨¡å‹å¤š GPU æ”¯æŒ: [#226](https://github.com/xorbitsai/inference/issues/226)
- Xinference ä»ªè¡¨ç›˜: [#93](https://github.com/xorbitsai/inference/issues/93)
### æ–°æ¨¡å‹
- å†…ç½® GGML æ ¼å¼çš„ Starcoder: [#289](https://github.com/xorbitsai/inference/pull/289)
- å†…ç½® [MusicGen](https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md): [#313](https://github.com/xorbitsai/inference/issues/313)
- å†…ç½® [SD-XL](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0): [#318](https://github.com/xorbitsai/inference/issues/318)
### å·¥å…·
- LlamaIndex æ’ä»¶: [#7151](https://github.com/jerryjliu/llama_index/pull/7151)



## ä¸»è¦åŠŸèƒ½
ğŸŒŸ **æ¨¡å‹æ¨ç†ï¼Œè½»è€Œæ˜“ä¸¾**ï¼šå¤§è¯­è¨€æ¨¡å‹ï¼Œè¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œå¤šæ¨¡æ€æ¨¡å‹çš„éƒ¨ç½²æµç¨‹è¢«å¤§å¤§ç®€åŒ–ã€‚ä¸€ä¸ªå‘½ä»¤å³å¯å®Œæˆæ¨¡å‹çš„éƒ¨ç½²å·¥ä½œã€‚ 

âš¡ï¸ **å‰æ²¿æ¨¡å‹ï¼Œåº”æœ‰å°½æœ‰**ï¼šæ¡†æ¶å†…ç½®ä¼—å¤šä¸­è‹±æ–‡çš„å‰æ²¿å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬ baichuanï¼Œchatglm2 ç­‰ï¼Œä¸€é”®å³å¯ä½“éªŒï¼å†…ç½®æ¨¡å‹åˆ—è¡¨è¿˜åœ¨å¿«é€Ÿæ›´æ–°ä¸­ï¼


ğŸ–¥ **å¼‚æ„ç¡¬ä»¶ï¼Œå¿«å¦‚é—ªç”µ**ï¼šé€šè¿‡ [ggml](https://github.com/ggerganov/ggml)ï¼ŒåŒæ—¶ä½¿ç”¨ä½ çš„ GPU ä¸ CPU è¿›è¡Œæ¨ç†ï¼Œé™ä½å»¶è¿Ÿï¼Œæé«˜ååï¼

âš™ï¸ **æ¥å£è°ƒç”¨ï¼Œçµæ´»å¤šæ ·**ï¼šæä¾›å¤šç§ä½¿ç”¨æ¨¡å‹çš„æ¥å£ï¼ŒåŒ…æ‹¬ RPCï¼ŒRESTful APIï¼Œå‘½ä»¤è¡Œï¼Œweb UI ç­‰ç­‰ã€‚æ–¹ä¾¿æ¨¡å‹çš„ç®¡ç†ä¸ç›‘æ§ã€‚

ğŸŒ **é›†ç¾¤è®¡ç®—ï¼Œåˆ†å¸ƒååŒ**: æ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²ï¼Œé€šè¿‡å†…ç½®çš„èµ„æºè°ƒåº¦å™¨ï¼Œè®©ä¸åŒå¤§å°çš„æ¨¡å‹æŒ‰éœ€è°ƒåº¦åˆ°ä¸åŒæœºå™¨ï¼Œå……åˆ†ä½¿ç”¨é›†ç¾¤èµ„æºã€‚

ğŸ”Œ **å¼€æ”¾ç”Ÿæ€ï¼Œæ— ç¼å¯¹æ¥**: ä¸æµè¡Œçš„ä¸‰æ–¹åº“æ— ç¼å¯¹æ¥ï¼ŒåŒ…æ‹¬ [LangChain](https://python.langchain.com/docs/integrations/providers/xinference) 
and [LlamaIndex](https://gpt-index.readthedocs.io/en/stable/examples/llm/XinferenceLocalDeployment.html#i-run-pip-install-xinference-all-in-a-terminal-window)ã€‚
è®©å¼€å‘è€…èƒ½å¤Ÿå¿«é€Ÿæ„å»ºåŸºäº AI çš„åº”ç”¨ã€‚

## å¿«é€Ÿå…¥é—¨
Xinference å¯ä»¥é€šè¿‡ pip ä» PyPI å®‰è£…ã€‚æˆ‘ä»¬éå¸¸æ¨èåœ¨å®‰è£…å‰åˆ›å»ºä¸€ä¸ªæ–°çš„è™šæ‹Ÿç¯å¢ƒä»¥é¿å…ä¾èµ–å†²çªã€‚

### å®‰è£…
```bash
$ pip install "xinference"
```
`xinference` å°†ä¼šå®‰è£…æ‰€æœ‰ç”¨äºæ¨ç†çš„åŸºç¡€ä¾èµ–ã€‚

#### æ”¯æŒ ggml æ¨ç†
æƒ³è¦åˆ©ç”¨ ggml æ¨ç†ï¼Œå¯ä»¥ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š
```bash
$ pip install "xinference[ggml]"
```
å¦‚æœä½ æƒ³è¦è·å¾—æ›´é«˜æ•ˆçš„åŠ é€Ÿï¼Œè¯·æŸ¥çœ‹ä¸‹åˆ—ä¾èµ–çš„å®‰è£…æ–‡æ¡£ï¼š
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python#installation-from-pypi-recommended) ç”¨äº `baichuan`, `wizardlm-v1.0`, `vicuna-v1.3` åŠ `orca`.
- [chatglm-cpp-python](https://github.com/li-plus/chatglm.cpp#getting-started) ç”¨äº `chatglm` åŠ `chatglm2`.

#### æ”¯æŒ PyTorch æ¨ç†
æƒ³è¦åˆ©ç”¨ PyTorch æ¨ç†ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š
```bash
$ pip install "xinference[pytorch]"
```

#### æ”¯æŒæ‰€æœ‰ç±»å‹
å¦‚æœæƒ³è¦æ”¯æŒæ¨ç†æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹ï¼Œå¯ä»¥å®‰è£…æ‰€æœ‰çš„ä¾èµ–ï¼š
```bash
$ pip install "xinference[all]"
```


### éƒ¨ç½²
ä½ å¯ä»¥ä¸€é”®è¿›è¡Œæœ¬åœ°éƒ¨ç½²ï¼Œæˆ–æŒ‰ç…§ä¸‹é¢çš„æ­¥éª¤å°† Xinference éƒ¨ç½²åœ¨è®¡ç®—é›†ç¾¤ã€‚ 

#### æœ¬åœ°éƒ¨ç½²
è¿è¡Œä¸‹é¢çš„å‘½ä»¤åœ¨æœ¬åœ°éƒ¨ç½² Xinferenceï¼š
```bash
$ xinference
```

#### åˆ†å¸ƒå¼éƒ¨ç½²
åˆ†å¸ƒå¼åœºæ™¯ä¸‹ï¼Œä½ éœ€è¦åœ¨ä¸€å°æœåŠ¡å™¨ä¸Šéƒ¨ç½²ä¸€ä¸ª Xinference supervisorï¼Œå¹¶åœ¨å…¶ä½™æœåŠ¡å™¨ä¸Šåˆ†åˆ«éƒ¨ç½²ä¸€ä¸ª Xinference workerã€‚ å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š

**å¯åŠ¨ supervisor**: æ‰§è¡Œ:
```bash
$ xinference-supervisor -H "${supervisor_host}"
```
æ›¿æ¢ `${supervisor_host}` ä¸º supervisor æ‰€åœ¨æœåŠ¡å™¨çš„å®é™…ä¸»æœºåæˆ– IP åœ°å€ã€‚

**å¯åŠ¨ workers**: åœ¨å…¶ä½™æœåŠ¡å™¨ä¸Šï¼Œæ‰§è¡Œï¼š
```bash
$ xinference-worker -e "http://${supervisor_host}:9997"
```

Xinference å¯åŠ¨åï¼Œå°†ä¼šæ‰“å°æœåŠ¡çš„ endpointã€‚è¿™ä¸ª endpoint ç”¨äºé€šè¿‡å‘½ä»¤è¡Œå·¥å…·æˆ–ç¼–ç¨‹æ¥å£è¿›è¡Œæ¨¡å‹çš„ç®¡ç†ã€‚

- æœ¬åœ°éƒ¨ç½²ä¸‹, endpoint é»˜è®¤ä¸º `http://localhost:9997`.
- é›†ç¾¤éƒ¨ç½²ä¸‹, endpoint é»˜è®¤ä¸º `http://${supervisor_host}:9997`ã€‚å…¶ä¸­ `${supervisor_host}` ä¸ºsupervisor æ‰€åœ¨æœåŠ¡å™¨çš„ä¸»æœºåæˆ– IP åœ°å€ã€‚

ä½ è¿˜å¯ä»¥é€šè¿‡ web UI ä¸ä»»æ„å†…ç½®æ¨¡å‹èŠå¤©ã€‚Xinference ç”šè‡³**æ”¯æŒåŒæ—¶ä¸ä¸¤ä¸ªæœ€å‰æ²¿çš„ AI æ¨¡å‹èŠå¤©å¹¶æ¯”è¾ƒå®ƒä»¬çš„å›å¤è´¨é‡**ï¼

![web UI](assets/demo.gif)

### Xinference å‘½ä»¤è¡Œ
Xinference æä¾›äº†å‘½ä»¤è¡Œå·¥å…·ç”¨äºæ¨¡å‹ç®¡ç†ã€‚æ”¯æŒçš„å‘½ä»¤åŒ…æ‹¬ï¼š

- å¯åŠ¨ä¸€ä¸ªæ¨¡å‹ (å°†ä¼šè¿”å›ä¸€ä¸ªæ¨¡å‹ UID)ï¼š`xinference launch`
- æŸ¥çœ‹æ‰€æœ‰è¿è¡Œä¸­çš„æ¨¡å‹ï¼š`xinference list`
- æŸ¥çœ‹æ‰€æœ‰å†…ç½®æ¨¡å‹ï¼š`xinference list --all`
- ç»“æŸæ¨¡å‹ï¼š`xinference terminate --model-uid ${model_uid}`

### Xinference ç¼–ç¨‹æ¥å£
Xinference åŒæ ·æä¾›äº†ç¼–ç¨‹æ¥å£ï¼š

```python
from xinference.client import Client

client = Client("http://localhost:9997")
model_uid = client.launch_model(model_name="chatglm2")
model = client.get_model(model_uid)

chat_history = []
prompt = "What is the largest animal?"
model.chat(
    prompt,
    chat_history,
    generate_config={"max_tokens": 1024}
)
```

è¿”å›å€¼ï¼š
```json
{
  "id": "chatcmpl-8d76b65a-bad0-42ef-912d-4a0533d90d61",
  "model": "56f69622-1e73-11ee-a3bd-9af9f16816c6",
  "object": "chat.completion",
  "created": 1688919187,
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The largest animal that has been scientifically measured is the blue whale, which has a maximum length of around 23 meters (75 feet) for adult animals and can weigh up to 150,000 pounds (68,000 kg). However, it is important to note that this is just an estimate and that the largest animal known to science may be larger still. Some scientists believe that the largest animals may not have a clear \"size\" in the same way that humans do, as their size can vary depending on the environment and the stage of their life."
      },
      "finish_reason": "None"
    }
  ],
  "usage": {
    "prompt_tokens": -1,
    "completion_tokens": -1,
    "total_tokens": -1
  }
}
```

è¯·å‚è€ƒ [æ›´å¤šæ¡ˆä¾‹](examples)ã€‚


## å†…ç½®æ¨¡å‹
è¿è¡Œä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹å†…ç½®æ¨¡å‹åˆ—è¡¨ï¼š
```bash
$ xinference list --all
```

| Name             | Language      | Ability                |
|------------------|---------------|------------------------|
| baichuan         | ['en', 'zh']  | ['embed', 'generate']  |
| baichuan-chat    | ['en', 'zh']  | ['embed', 'chat']      |
| chatglm          | ['en', 'zh']  | ['embed', 'chat']      |
| chatglm2         | ['en', 'zh']  | ['embed', 'chat']      |
| chatglm2-32k     | ['en', 'zh']  | ['embed', 'chat']      |
| falcon           | ['en']        | ['embed', 'generate']  |
| falcon-instruct  | ['en']        | ['embed', 'chat']      |
| gpt-2            | ['en']        | ['generate']           |
| internlm         | ['en', 'zh']  | ['embed', 'generate']  |
| internlm-chat    | ['en', 'zh']  | ['embed', 'chat']      |
| internlm-chat-8k | ['en', 'zh']  | ['embed', 'chat']      |
| llama-2          | ['en']        | ['embed', 'generate']  |
| llama-2-chat     | ['en']        | ['embed', 'chat']      |
| opt              | ['en']        | ['embed', 'generate']  |
| orca             | ['en']        | ['embed', 'chat']      |
| qwen-chat        | ['en', 'zh']  | ['embed', 'chat']      |
| starchat-beta    | ['en']        | ['embed', 'chat']      |
| starcoder        | ['en']        | ['generate']           |
| starcoderplus    | ['en']        | ['embed', 'generate']  |
| vicuna-v1.3      | ['en']        | ['embed', 'chat']      |
| vicuna-v1.5      | ['en']        | ['embed', 'chat']      |
| vicuna-v1.5-16k  | ['en']        | ['embed', 'chat']      |
| wizardlm-v1.0    | ['en']        | ['embed', 'chat']      |
| wizardmath-v1.0  | ['en']        | ['embed', 'chat']      |

æ›´å¤šä¿¡æ¯è¯·å‚è€ƒ [å†…ç½®æ¨¡å‹](https://inference.readthedocs.io/en/latest/models/builtin/index.html)ã€‚

**æ³¨æ„**:
- Xinference ä¼šè‡ªåŠ¨ä¸ºä½ ä¸‹è½½æ¨¡å‹ï¼Œé»˜è®¤çš„æ¨¡å‹å­˜æ”¾è·¯å¾„ä¸º `${USER}/.xinference/cache`ã€‚

## è‡ªå®šä¹‰æ¨¡å‹
è¯·å‚è€ƒ [è‡ªå®šä¹‰æ¨¡å‹](https://inference.readthedocs.io/en/latest/models/custom.html)ã€‚
