<div align="center">
<img src="./assets/xorbits-logo.png" width="180px" alt="xorbits" />

# Xorbits Inferenceï¼šæ¨¡å‹æ¨ç†ï¼Œ è½»è€Œæ˜“ä¸¾ ğŸ¤–

[![PyPI Latest Release](https://img.shields.io/pypi/v/xinference.svg?style=for-the-badge)](https://pypi.org/project/xinference/)
[![License](https://img.shields.io/pypi/l/xinference.svg?style=for-the-badge)](https://github.com/xorbitsai/inference/blob/main/LICENSE)
[![Build Status](https://img.shields.io/github/actions/workflow/status/xorbitsai/inference/python.yaml?branch=main&style=for-the-badge&label=GITHUB%20ACTIONS&logo=github)](https://actions-badge.atrox.dev/xorbitsai/inference/goto?ref=main)
[![Slack](https://img.shields.io/badge/join_Slack-781FF5.svg?logo=slack&style=for-the-badge)](https://join.slack.com/t/xorbitsio/shared_invite/zt-1o3z9ucdh-RbfhbPVpx7prOVdM1CAuxg)
[![Twitter](https://img.shields.io/twitter/follow/xorbitsio?logo=twitter&style=for-the-badge)](https://twitter.com/xorbitsio)

[English](README.md) | ä¸­æ–‡ä»‹ç»
</div>
<br />


Xorbits Inferenceï¼ˆXinferenceï¼‰æ˜¯ä¸€ä¸ªæ€§èƒ½å¼ºå¤§ä¸”åŠŸèƒ½å…¨é¢çš„åˆ†å¸ƒå¼æ¨ç†æ¡†æ¶ã€‚å¯ç”¨äºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œè¯­éŸ³è¯†åˆ«æ¨¡
å‹ï¼Œå¤šæ¨¡æ€æ¨¡å‹ç­‰å„ç§æ¨¡å‹çš„æ¨ç†ã€‚é€šè¿‡ Xorbits Inferenceï¼Œä½ å¯ä»¥è½»æ¾åœ°ä¸€é”®éƒ¨ç½²ä½ è‡ªå·±çš„æ¨¡å‹ï¼Œæˆ–å†…ç½®çš„å‰æ²¿å¼€æºæ¨¡å‹ã€‚
æ— è®ºä½ æ˜¯ç ”ç©¶è€…ï¼Œå¼€å‘è€…ï¼Œæˆ–æ˜¯æ•°æ®ç§‘å­¦å®¶ï¼Œéƒ½å¯ä»¥é€šè¿‡ Xorbits Inference ä¸æœ€å‰æ²¿çš„ AI æ¨¡å‹ï¼Œå‘æ˜æ›´å¤šå¯èƒ½ã€‚


![demo](assets/demo.gif)

<div align="center">
<i><a href="https://join.slack.com/t/xorbitsio/shared_invite/zt-1z3zsm9ep-87yI9YZ_B79HLB2ccTq4WA">ğŸ‘‰ ç«‹åˆ»åŠ å…¥æˆ‘ä»¬çš„ Slack ç¤¾åŒº!</a></i>
</div>


## ä¸»è¦åŠŸèƒ½
ğŸŒŸ **æ¨¡å‹æ¨ç†ï¼Œè½»è€Œæ˜“ä¸¾**ï¼šå¤§è¯­è¨€æ¨¡å‹ï¼Œè¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œå¤šæ¨¡æ€æ¨¡å‹çš„éƒ¨ç½²æµç¨‹è¢«å¤§å¤§ç®€åŒ–ã€‚ä¸€ä¸ªå‘½ä»¤å³å¯å®Œæˆæ¨¡å‹
çš„éƒ¨ç½²å·¥ä½œã€‚ 

âš¡ï¸ **å‰æ²¿æ¨¡å‹ï¼Œåº”æœ‰å°½æœ‰**ï¼šæ¡†æ¶å†…ç½®ä¼—å¤šä¸­è‹±æ–‡çš„å‰æ²¿å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬ baichuanï¼Œchatglm2 ç­‰ï¼Œä¸€é”®å³å¯ä½“éªŒï¼å†…ç½®
æ¨¡å‹åˆ—è¡¨è¿˜åœ¨å¿«é€Ÿæ›´æ–°ä¸­ï¼


ğŸ–¥ **å¼‚æ„ç¡¬ä»¶ï¼Œå¿«å¦‚é—ªç”µ**ï¼šé€šè¿‡ [ggml](https://github.com/ggerganov/ggml)ï¼ŒåŒæ—¶ä½¿ç”¨ä½ çš„ GPU ä¸ CPU è¿›è¡Œæ¨
ç†ï¼Œé™ä½å»¶è¿Ÿï¼Œæé«˜ååï¼

âš™ï¸ **æ¥å£è°ƒç”¨ï¼Œçµæ´»å¤šæ ·**ï¼šæä¾›å¤šç§ä½¿ç”¨æ¨¡å‹çš„æ¥å£ï¼ŒåŒ…æ‹¬ RPCï¼ŒRESTful APIï¼Œå‘½ä»¤è¡Œï¼Œweb UI ç­‰ç­‰ã€‚æ–¹ä¾¿æ¨¡å‹çš„ç®¡ç†
ä¸ç›‘æ§ã€‚

ğŸŒ **é›†ç¾¤è®¡ç®—ï¼Œåˆ†å¸ƒååŒ**: æ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²ï¼Œé€šè¿‡å†…ç½®çš„èµ„æºè°ƒåº¦å™¨ï¼Œè®©ä¸åŒå¤§å°çš„æ¨¡å‹æŒ‰éœ€è°ƒåº¦åˆ°ä¸åŒæœºå™¨ï¼Œå……åˆ†ä½¿ç”¨é›†
ç¾¤èµ„æºã€‚

ğŸ”Œ **å¼€æ”¾ç”Ÿæ€ï¼Œæ— ç¼å¯¹æ¥**: ä¸æµè¡Œçš„ä¸‰æ–¹åº“æ— ç¼å¯¹æ¥ï¼ŒåŒ…æ‹¬ LangChainï¼ŒLlamaIndex ç­‰ï¼ˆå³å°†åˆ°æ¥ï¼‰ã€‚è®©å¼€å‘è€…èƒ½å¤Ÿå¿«
é€Ÿæ„å»ºåŸºäº AI çš„åº”ç”¨ã€‚

## å¿«é€Ÿå…¥é—¨
Xinference å¯ä»¥é€šè¿‡ pip ä» PyPI å®‰è£…ã€‚æˆ‘ä»¬éå¸¸æ¨èåœ¨å®‰è£…å‰åˆ›å»ºä¸€ä¸ªæ–°çš„è™šæ‹Ÿç¯å¢ƒä»¥é¿å…ä¾èµ–å†²çªã€‚
```bash
$ pip install "xinference[all]"
```
`xinference[all]` å°†ä¼šå®‰è£…æ‰€æœ‰ç”¨äºæ¨ç†çš„å¿…è¦ä¾èµ–ã€‚å¦‚æœä½ æƒ³è¦è·å¾—æ›´é«˜æ•ˆçš„åŠ é€Ÿï¼Œè¯·æŸ¥çœ‹ä¸‹åˆ—ä¾èµ–çš„å®‰è£…æ–‡æ¡£ï¼š
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python#installation-from-pypi-recommended) ç”¨äº `baichuan`, `wizardlm-v1.0`, `vicuna-v1.3` åŠ `orca`.
- [chatglm-cpp-python](https://github.com/li-plus/chatglm.cpp#getting-started) ç”¨äº `chatglm` åŠ `chatglm2`.


### éƒ¨ç½²
ä½ å¯ä»¥ä¸€é”®è¿›è¡Œæœ¬åœ°éƒ¨ç½²ï¼Œæˆ–æŒ‰ç…§ä¸‹é¢çš„æ­¥éª¤å°† Xinference éƒ¨ç½²åœ¨è®¡ç®—é›†ç¾¤ã€‚ 

#### æœ¬åœ°éƒ¨ç½²
è¿è¡Œä¸‹é¢çš„å‘½ä»¤åœ¨æœ¬åœ°éƒ¨ç½² Xinferenceï¼š
```bash
$ xinference
```

#### åˆ†å¸ƒå¼éƒ¨ç½²
åˆ†å¸ƒå¼åœºæ™¯ä¸‹ï¼Œä½ éœ€è¦åœ¨ä¸€å°æœåŠ¡å™¨ä¸Šéƒ¨ç½²ä¸€ä¸ª Xinference supervisorï¼Œå¹¶åœ¨å…¶ä½™æœåŠ¡å™¨ä¸Šåˆ†åˆ«éƒ¨ç½²ä¸€ä¸ª Xinference
workerã€‚ å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š

**å¯åŠ¨ supervisor**: æ‰§è¡Œ:
```bash
$ xinference-supervisor -H "${supervisor_host}"
```
æ›¿æ¢ `${supervisor_host}` ä¸º supervisor æ‰€åœ¨æœåŠ¡å™¨çš„å®é™…ä¸»æœºåæˆ– IP åœ°å€ã€‚

**å¯åŠ¨ workers**: åœ¨å…¶ä½™æœåŠ¡å™¨ä¸Šï¼Œæ‰§è¡Œï¼š
```bash
$ xinference-worker -e "http://${supervisor_host}:9997"
```

Xinference å¯åŠ¨åï¼Œå°†ä¼šæ‰“å°æœåŠ¡çš„ endpointã€‚è¿™ä¸ª endpoint ç”¨äºé€šè¿‡å‘½ä»¤è¡Œå·¥å…·æˆ–ç¼–ç¨‹æ¥å£è¿›è¡Œæ¨¡å‹çš„ç®¡ç†ã€‚

- æœ¬åœ°éƒ¨ç½²ä¸‹, endpoint é»˜è®¤ä¸º `http://localhost:9997`.
- é›†ç¾¤éƒ¨ç½²ä¸‹, endpoint é»˜è®¤ä¸º `http://${supervisor_host}:9997`ã€‚å…¶ä¸­ `${supervisor_host}` ä¸º
supervisor æ‰€åœ¨æœåŠ¡å™¨çš„ä¸»æœºåæˆ– IP åœ°å€ã€‚

ä½ è¿˜å¯ä»¥é€šè¿‡ web UI ä¸ä»»æ„å†…ç½®æ¨¡å‹èŠå¤©ã€‚Xinference ç”šè‡³**æ”¯æŒåŒæ—¶ä¸ä¸¤ä¸ªæœ€å‰æ²¿çš„ AI æ¨¡å‹èŠå¤©å¹¶æ¯”è¾ƒå®ƒä»¬çš„å›å¤è´¨
é‡**ï¼

![web UI](assets/xinference-downloading.png)

### Xinference å‘½ä»¤è¡Œ
Xinference æä¾›äº†å‘½ä»¤è¡Œå·¥å…·ç”¨äºæ¨¡å‹ç®¡ç†ã€‚æ”¯æŒçš„å‘½ä»¤åŒ…æ‹¬ï¼š

- å¯åŠ¨ä¸€ä¸ªæ¨¡å‹ (å°†ä¼šè¿”å›ä¸€ä¸ªæ¨¡å‹ UID)ï¼š`xinference launch`
- æŸ¥çœ‹æ‰€æœ‰è¿è¡Œä¸­çš„æ¨¡å‹ï¼š`xinference list`
- æŸ¥çœ‹æ‰€æœ‰å†…ç½®æ¨¡å‹ï¼š`xinference list --all`
- ç»“æŸæ¨¡å‹ï¼š`xinference terminate --model-uid ${model_uid}`

### Xinference ç¼–ç¨‹æ¥å£
Xinference åŒæ ·æä¾›äº†ç¼–ç¨‹æ¥å£ï¼š

```python
from xinference.client import Client

client = Client("http://localhost:9997")
model_uid = client.launch_model(model_name="chatglm2")
model = client.get_model(model_uid)

chat_history = []
prompt = "What is the largest animal?"
model.chat(
            prompt,
            chat_history,
            generate_config={"max_tokens": 1024}
        )
```

è¿”å›å€¼ï¼š
```json
{
  "id": "chatcmpl-8d76b65a-bad0-42ef-912d-4a0533d90d61",
  "model": "56f69622-1e73-11ee-a3bd-9af9f16816c6",
  "object": "chat.completion",
  "created": 1688919187,
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The largest animal that has been scientifically measured is the blue whale, which has a maximum length of around 23 meters (75 feet) for adult animals and can weigh up to 150,000 pounds (68,000 kg). However, it is important to note that this is just an estimate and that the largest animal known to science may be larger still. Some scientists believe that the largest animals may not have a clear \"size\" in the same way that humans do, as their size can vary depending on the environment and the stage of their life."
      },
      "finish_reason": "None"
    }
  ],
  "usage": {
    "prompt_tokens": -1,
    "completion_tokens": -1,
    "total_tokens": -1
  }
}
```

è¯·å‚è€ƒ [æ›´å¤šæ¡ˆä¾‹](examples)ã€‚


## å†…ç½®æ¨¡å‹
è¿è¡Œä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹å†…ç½®æ¨¡å‹åˆ—è¡¨ï¼š
```bash
$ xinference list --all
```

| Name                 | Type             | Language | Format | Size (in billions) | Quantization                           |
| -------------------- |------------------|----------|--------|--------------------|----------------------------------------|
| baichuan             | Foundation Model | en, zh   | ggmlv3 | 7                  | 'q2_K', 'q3_K_L', ... , 'q6_K', 'q8_0' |
| chatglm              | SFT Model        | en, zh   | ggmlv3 | 6                  | 'q4_0', 'q4_1', 'q5_0', 'q5_1', 'q8_0' |
| chatglm2             | SFT Model        | en, zh   | ggmlv3 | 6                  | 'q4_0', 'q4_1', 'q5_0', 'q5_1', 'q8_0' |
| wizardlm-v1.0        | SFT Model        | en       | ggmlv3 | 7, 13, 33          | 'q2_K', 'q3_K_L', ... , 'q6_K', 'q8_0' |
| wizardlm-v1.1        | SFT Model        | en       | ggmlv3 | 13                 | 'q2_K', 'q3_K_L', ... , 'q6_K', 'q8_0' |
| vicuna-v1.3          | SFT Model        | en       | ggmlv3 | 7, 13              | 'q2_K', 'q3_K_L', ... , 'q6_K', 'q8_0' |
| orca                 | SFT Model        | en       | ggmlv3 | 3, 7, 13           | 'q4_0', 'q4_1', 'q5_0', 'q5_1', 'q8_0' |


**æ³¨æ„**:
- Xinference ä¼šè‡ªåŠ¨ä¸ºä½ ä¸‹è½½æ¨¡å‹ï¼Œé»˜è®¤çš„æ¨¡å‹å­˜æ”¾è·¯å¾„ä¸º `${USER}/.xinference/cache`ã€‚
- åŸºç¡€æ¨¡å‹ä»…æä¾› `generate` æ¥å£.
- SFT æ¨¡å‹ æä¾› `generate` ä¸ `chat` æ¥å£ã€‚

## è¿‘æœŸå¼€å‘è®¡åˆ’
Xinference ç›®å‰æ­£åœ¨å¿«é€Ÿè¿­ä»£ã€‚æˆ‘ä»¬è¿‘æœŸçš„å¼€å‘è®¡åˆ’åŒ…æ‹¬ï¼š

### PyTorch æ”¯æŒ
é€šè¿‡ PyTorch é›†æˆ, ç”¨æˆ·å°†å¯ä»¥åœ¨ Xinference ä¸­æ— ç¼ä½¿ç”¨æ¥è‡ª Hugging Face çš„å¤§é‡å¼€æºæ¨¡å‹ã€‚

### Langchain & LlamaIndex integration
é€šè¿‡ä¸ Langchain åŠ LlamaIndex é›†æˆï¼Œç”¨æˆ·å°†èƒ½å¤Ÿé€šè¿‡ Xinferenceï¼ŒåŸºäºå¼€æºæ¨¡å‹å¿«é€Ÿæ„å»º AI åº”ç”¨ã€‚ 

