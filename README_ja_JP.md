<div align="center">
<img src="./assets/xorbits-logo.png" width="180px" alt="xorbits" />

# Xorbits Inference: ãƒ¢ãƒ‡ãƒ«ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã‚’ç°¡å˜ã« ğŸ¤–

[![PyPI Latest Release](https://img.shields.io/pypi/v/xinference.svg?style=for-the-badge)](https://pypi.org/project/xinference/)
[![License](https://img.shields.io/pypi/l/xinference.svg?style=for-the-badge)](https://github.com/xorbitsai/inference/blob/main/LICENSE)
[![Build Status](https://img.shields.io/github/actions/workflow/status/xorbitsai/inference/python.yaml?branch=main&style=for-the-badge&label=GITHUB%20ACTIONS&logo=github)](https://actions-badge.atrox.dev/xorbitsai/inference/goto?ref=main)
[![Slack](https://img.shields.io/badge/join_Slack-781FF5.svg?logo=slack&style=for-the-badge)](https://join.slack.com/t/xorbitsio/shared_invite/zt-1o3z9ucdh-RbfhbPVpx7prOVdM1CAuxg)
[![Twitter](https://img.shields.io/twitter/follow/xorbitsio?logo=twitter&style=for-the-badge)](https://twitter.com/xorbitsio)

[English](README.md) | [ä¸­æ–‡ä»‹ç»](README_zh_CN.md) | æ—¥æœ¬èª
</div>
<br />


Xorbits Inference(Xinference) ã¯ã€è¨€èªã€éŸ³å£°èªè­˜ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã«
è¨­è¨ˆã•ã‚ŒãŸå¼·åŠ›ã§æ±ç”¨æ€§ã®é«˜ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚ Xorbits Inference ã‚’ä½¿ãˆã°ã€ãŸã£ãŸ 1 ã¤ã®ã‚³ãƒãƒ³ãƒ‰ã§ã€
ã‚ãªãŸã‚„æœ€å…ˆç«¯ã®ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã€æä¾›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ Xorbits Inference ã¯ã€
ç ”ç©¶è€…ã€é–‹ç™ºè€…ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã‚’å•ã‚ãšã€æœ€å…ˆç«¯ã® AI ãƒ¢ãƒ‡ãƒ«ã®å¯èƒ½æ€§ã‚’æœ€å¤§é™ã«å¼•ãå‡ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚

<div align="center">
<i><a href="https://join.slack.com/t/xorbitsio/shared_invite/zt-1z3zsm9ep-87yI9YZ_B79HLB2ccTq4WA">ğŸ‘‰ Slack ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ã”å‚åŠ ãã ã•ã„ï¼</a></i>
</div>


## ä¸»ãªç‰¹å¾´
ğŸŒŸ **ãƒ¢ãƒ‡ãƒ«ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã‚’ç°¡å˜ã«**: å¤§è¦æ¨¡ãªè¨€èªã€éŸ³å£°èªè­˜ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æä¾›ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç°¡ç´ åŒ–ã—ã¾ã™ã€‚
1ã¤ã®ã‚³ãƒãƒ³ãƒ‰ã§ã€å®Ÿé¨“ç”¨ã¨æœ¬ç•ªç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã¾ã™ã€‚

âš¡ï¸ **æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«**: ã‚³ãƒãƒ³ãƒ‰1ã¤ã§æœ€å…ˆç«¯ã®ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿé¨“ã€‚
Inference ã¯ã€æœ€å…ˆç«¯ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’æä¾›ã—ã¾ã™ï¼

ğŸ–¥ **ç•°æ©Ÿç¨®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®åˆ©ç”¨**: [ggml](https://github.com/ggerganov/ggml) ã§ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒªã‚½ãƒ¼ã‚¹ã‚’æœ€å¤§é™ã«æ´»ç”¨ã—ã¾ã—ã‚‡ã†ã€‚
Xorbits Inference ã¯ã€GPU ã‚„ CPU ã‚’å«ã‚€ç•°ç¨®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã«åˆ©ç”¨ã—ã€ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚¿ã‚¹ã‚¯ã‚’é«˜é€ŸåŒ–ã—ã¾ã™ã€‚

âš™ï¸ **æŸ”è»Ÿãª API ã¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**: ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ãªç®¡ç†ã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã®ãŸã‚ã«ã€RPCã€
RESTful APIï¼ˆOpenAI API ã¨äº’æ›æ€§ã‚ã‚Šï¼‰ã€CLIã€WebUI ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

ğŸŒ **é…å¸ƒãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ**: Excel ã®åˆ†æ•£å±•é–‹ã‚·ãƒŠãƒªã‚ªã§ã¯ã€è¤‡æ•°ã®ãƒ‡ãƒã‚¤ã‚¹ã‚„ãƒã‚·ãƒ³ã«ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«åˆ†æ•£ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

ğŸ”Œ **ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã®çµ„ã¿è¾¼ã¿çµ±åˆ**: Xorbits Inference ã¯ã€[LangChain](https://python.langchain.com/docs/integrations/providers/xinference)
ã‚„ [LlamaIndex](https://gpt-index.readthedocs.io/en/stable/examples/llm/XinferenceLocalDeployment.html#i-run-pip-install-xinference-all-in-a-terminal-window) ã®ã‚ˆã†ãªäººæ°—ã®ã‚ã‚‹ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨
ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚

## ã¯ã˜ã‚ã«
Xinference ã¯ PyPI ã‹ã‚‰ pip çµŒç”±ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆã‚’é¿ã‘ã‚‹ãŸã‚ã€æ–°ã—ã„ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
$ pip install "xinference"
```
`xinference` ã¯ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã™ã‚‹ãŸã‚ã®åŸºæœ¬çš„ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

#### GGML ã§ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
ggml ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã™ã‚‹ãŸã‚ã«ã¯ã€ä»¥ä¸‹ã®è¿½åŠ ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:
```bash
$ pip install "xinference[ggml]"
```
ç•°ãªã‚‹ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ã—ãŸã„å ´åˆã¯ã€
å¯¾å¿œã™ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
- `baichuan`ã€`wizardlm-v1.0`ã€`vicuna-v1.3`ã€`orca` ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€[llama-cpp-python](https://github.com/abetlen/llama-cpp-python#installation-from-pypi-recommended) ãŒå¿…è¦ã§ã‚ã‚‹ã€‚
- `chatglm` ã¨ `chatglm2` ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€[chatglm-cpp-python](https://github.com/li-plus/chatglm.cpp#getting-started) ãŒå¿…è¦ã§ã‚ã‚‹ã€‚

#### PyTorch ã§ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
PyTorch ã®ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:
```bash
$ pip install "xinference[pytorch]"
```

#### ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ã‚’å«ã‚€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã«ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ãŸã„å ´åˆã¯ã€ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™:
```bash
$ pip install "xinference[all]"
```


### ãƒ‡ãƒ—ãƒ­ã‚¤
Xinference ã¯ã€1 ã¤ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã“ã¨ã‚‚ã€åˆ†æ•£ã‚¯ãƒ©ã‚¹ã‚¿ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

#### ãƒ­ãƒ¼ã‚«ãƒ«
Xinference ã®ãƒ­ãƒ¼ã‚«ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’èµ·å‹•ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™:
```bash
$ xinference
```

#### é…å¸ƒ

Xinference ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ã«å±•é–‹ã™ã‚‹ã«ã¯ã€1 å°ã®ã‚µãƒ¼ãƒãƒ¼ã§ Xinference supervisor ã‚’èµ·å‹•ã—ã€ä»–ã®ã‚µãƒ¼ãƒãƒ¼ã§
Xinference workers ã‚’èµ·å‹•ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã®æ‰‹é †ã«å¾“ã£ã¦ãã ã•ã„:

**supervisor ã®ã‚¹ã‚¿ãƒ¼ãƒˆ**: Xinference supervisor ã‚’å®Ÿè¡Œã™ã‚‹ã‚µãƒ¼ãƒãƒ¼ã§ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™:
```bash
$ xinference-supervisor -H "${supervisor_host}"
```
`${supervisor_host}` ã‚’å®Ÿéš›ã® supervisor ã‚µãƒ¼ãƒã®ãƒ›ã‚¹ãƒˆã«ç½®ãæ›ãˆã¾ã™ã€‚

**Workers ã®ã‚¹ã‚¿ãƒ¼ãƒˆ**: Xinference ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’å®Ÿè¡Œã—ãŸã„ä»–ã®å„ã‚µãƒ¼ãƒãƒ¼ã§ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™:
```bash
$ xinference-worker -e "http://${supervisor_host}:9997"
```

Xinference ãŒèµ·å‹•ã™ã‚‹ã¨ã€CLI ã¾ãŸã¯ Xinference ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®ãŸã‚ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

- ãƒ­ãƒ¼ã‚«ãƒ«é…ç½®ã®å ´åˆã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯ `http://localhost:9997` ã¨ãªã‚Šã¾ã™ã€‚
- ã‚¯ãƒ©ã‚¹ã‚¿å±•é–‹ã®å ´åˆã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯ `http://${supervisor_host}:9997` ã«ãªã‚Šã¾ã™ã€‚
`${supervisor_host}` ã¯ supervisor ãŒç¨¼å‹•ã—ã¦ã„ã‚‹ã‚µãƒ¼ãƒã®ãƒ›ã‚¹ãƒˆåã¾ãŸã¯ IP ã‚¢ãƒ‰ãƒ¬ã‚¹ã§ã™ã€‚

ã¾ãŸã€Xinference ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ã‚¦ã‚§ãƒ– UI ã‚’è¡¨ç¤ºã—ã€ã™ã¹ã¦ã®å†…è”µãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ£ãƒƒãƒˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

![web UI](assets/index.jpg)

### Xinference CLI
Xinference ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®ãŸã‚ã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆCLIï¼‰ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¾¿åˆ©ãªã‚³ãƒãƒ³ãƒ‰ã‚’ã„ãã¤ã‹ç´¹ä»‹ã—ã¾ã™:

- ãƒ¢ãƒ‡ãƒ«ã‚’èµ·å‹•ã™ã‚‹ï¼ˆãƒ¢ãƒ‡ãƒ«ã® UID ãŒè¿”ã•ã‚Œã‚‹ï¼‰: `xinference launch`
- å®Ÿè¡Œä¸­ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹: `xinference list`
- å…¨ã¦ã®ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹: `xinference registrations`
- ãƒ¢ãƒ‡ãƒ«ã‚’çµ‚äº†ã™ã‚‹ï¼š ãƒ¢ãƒ‡ãƒ«ã®çµ‚äº†: `xinference terminate --model-uid ${model_uid}`

### Xinference ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
Xinference ã¯ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ãƒ¢ãƒ‡ãƒ«ã‚’ç®¡ç†ã—ã€ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚‚æä¾›ã—ã¦ã„ã¾ã™:

```python
from xinference.client import Client

client = Client("http://localhost:9997")
model_uid = client.launch_model(model_name="chatglm2")
model = client.get_model(model_uid)

chat_history = []
prompt = "What is the largest animal?"
model.chat(
    prompt,
    chat_history,
    generate_config={"max_tokens": 1024}
)
```

çµæœ:
```json
{
  "id": "chatcmpl-8d76b65a-bad0-42ef-912d-4a0533d90d61",
  "model": "56f69622-1e73-11ee-a3bd-9af9f16816c6",
  "object": "chat.completion",
  "created": 1688919187,
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The largest animal that has been scientifically measured is the blue whale, which has a maximum length of around 23 meters (75 feet) for adult animals and can weigh up to 150,000 pounds (68,000 kg). However, it is important to note that this is just an estimate and that the largest animal known to science may be larger still. Some scientists believe that the largest animals may not have a clear \"size\" in the same way that humans do, as their size can vary depending on the environment and the stage of their life."
      },
      "finish_reason": "None"
    }
  ],
  "usage": {
    "prompt_tokens": -1,
    "completion_tokens": -1,
    "total_tokens": -1
  }
}
```

ãã®ä»–ã®ä¾‹ã¯ [examples](ä¾‹) ã‚’å‚ç…§ã€‚


## å†…è”µãƒ¢ãƒ‡ãƒ«
å†…è”µãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™:
```bash
$ xinference registrations
```

| Type | Name                | Language     | Ability                |
|------|---------------------|--------------|------------------------|
| LLM  | baichuan            | ['en', 'zh'] | ['embed', 'generate']  |
| LLM  | baichuan-2          | ['en', 'zh'] | ['embed', 'generate']  |
| LLM  | baichuan-chat       | ['en', 'zh'] | ['embed', 'chat']      |
| LLM  | baichuan-2-chat     | ['en', 'zh'] | ['embed', 'chat']      |
| LLM  | chatglm             | ['en', 'zh'] | ['embed', 'chat']      |
| LLM  | chatglm2            | ['en', 'zh'] | ['embed', 'chat']      |
| LLM  | chatglm2-32k        | ['en', 'zh'] | ['embed', 'chat']      |
| LLM  | code-llama          | ['en']       | ['generate']           |
| LLM  | code-llama-instruct | ['en']       | ['chat']               |
| LLM  | code-llama-python   | ['en']       | ['generate']           |
| LLM  | falcon              | ['en']       | ['embed', 'generate']  |
| LLM  | falcon-instruct     | ['en']       | ['embed', 'chat']      |
| LLM  | gpt-2               | ['en']       | ['generate']           |
| LLM  | internlm            | ['en', 'zh'] | ['embed', 'generate']  |
| LLM  | internlm-chat       | ['en', 'zh'] | ['embed', 'chat']      |
| LLM  | internlm-chat-8k    | ['en', 'zh'] | ['embed', 'chat']      |
| LLM  | llama-2             | ['en']       | ['embed', 'generate']  |
| LLM  | llama-2-chat        | ['en']       | ['embed', 'chat']      |
| LLM  | opt                 | ['en']       | ['embed', 'generate']  |
| LLM  | orca                | ['en']       | ['embed', 'chat']      |
| LLM  | qwen-chat           | ['en', 'zh'] | ['embed', 'chat']      |
| LLM  | starchat-beta       | ['en']       | ['embed', 'chat']      |
| LLM  | starcoder           | ['en']       | ['generate']           |
| LLM  | starcoderplus       | ['en']       | ['embed', 'generate']  |
| LLM  | vicuna-v1.3         | ['en']       | ['embed', 'chat']      |
| LLM  | vicuna-v1.5         | ['en']       | ['embed', 'chat']      |
| LLM  | vicuna-v1.5-16k     | ['en']       | ['embed', 'chat']      |
| LLM  | wizardlm-v1.0       | ['en']       | ['embed', 'chat']      |
| LLM  | wizardmath-v1.0     | ['en']       | ['embed', 'chat']      |

**æ³¨**:
- Xinference ã¯è‡ªå‹•çš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ `${USER}/.xinference/cache` ã®ä¸‹ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚
- Hugging Face ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹éš›ã«å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ `export XINFERENCE_MODEL_SRC=xorbits` ã‚’å®Ÿè¡Œã—ã¦ã€ãƒŸãƒ©ãƒ¼ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚

## ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«
[ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«](https://inference.readthedocs.io/en/latest/models/custom.html)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚




