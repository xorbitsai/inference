<div align="center">
<img src="./assets/xorbits-logo.png" width="180px" alt="xorbits" />

# Xorbits Inference: ãƒ¢ãƒ‡ãƒ«ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã‚’ç°¡å˜ã« ğŸ¤–

[![PyPI Latest Release](https://img.shields.io/pypi/v/xinference.svg?style=for-the-badge)](https://pypi.org/project/xinference/)
[![License](https://img.shields.io/pypi/l/xinference.svg?style=for-the-badge)](https://github.com/xorbitsai/inference/blob/main/LICENSE)
[![Build Status](https://img.shields.io/github/actions/workflow/status/xorbitsai/inference/python.yaml?branch=main&style=for-the-badge&label=GITHUB%20ACTIONS&logo=github)](https://actions-badge.atrox.dev/xorbitsai/inference/goto?ref=main)
[![Slack](https://img.shields.io/badge/join_Slack-781FF5.svg?logo=slack&style=for-the-badge)](https://join.slack.com/t/xorbitsio/shared_invite/zt-1o3z9ucdh-RbfhbPVpx7prOVdM1CAuxg)
[![Twitter](https://img.shields.io/twitter/follow/xorbitsio?logo=twitter&style=for-the-badge)](https://twitter.com/xorbitsio)

[English](README.md) | [ä¸­æ–‡ä»‹ç»](README_zh_CN.md) | æ—¥æœ¬èª
</div>
<br />


Xorbits Inference(Xinference) ã¯ã€è¨€èªã€éŸ³å£°èªè­˜ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã«
è¨­è¨ˆã•ã‚ŒãŸå¼·åŠ›ã§æ±ç”¨æ€§ã®é«˜ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚ Xorbits Inference ã‚’ä½¿ãˆã°ã€ãŸã£ãŸ 1 ã¤ã®ã‚³ãƒãƒ³ãƒ‰ã§ã€
ã‚ãªãŸã‚„æœ€å…ˆç«¯ã®ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã€æä¾›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ Xorbits Inference ã¯ã€
ç ”ç©¶è€…ã€é–‹ç™ºè€…ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã‚’å•ã‚ãšã€æœ€å…ˆç«¯ã® AI ãƒ¢ãƒ‡ãƒ«ã®å¯èƒ½æ€§ã‚’æœ€å¤§é™ã«å¼•ãå‡ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚

<div align="center">
<i><a href="https://join.slack.com/t/xorbitsio/shared_invite/zt-1z3zsm9ep-87yI9YZ_B79HLB2ccTq4WA">ğŸ‘‰ Slack ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ã”å‚åŠ ãã ã•ã„ï¼</a></i>
</div>


## ä¸»ãªç‰¹å¾´
ğŸŒŸ **ãƒ¢ãƒ‡ãƒ«ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã‚’ç°¡å˜ã«**: å¤§è¦æ¨¡ãªè¨€èªã€éŸ³å£°èªè­˜ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æä¾›ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç°¡ç´ åŒ–ã—ã¾ã™ã€‚
1ã¤ã®ã‚³ãƒãƒ³ãƒ‰ã§ã€å®Ÿé¨“ç”¨ã¨æœ¬ç•ªç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã¾ã™ã€‚

âš¡ï¸ **æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«**: ã‚³ãƒãƒ³ãƒ‰1ã¤ã§æœ€å…ˆç«¯ã®ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿé¨“ã€‚
Inference ã¯ã€æœ€å…ˆç«¯ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’æä¾›ã—ã¾ã™ï¼

ğŸ–¥ **ç•°æ©Ÿç¨®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®åˆ©ç”¨**: [ggml](https://github.com/ggerganov/ggml) ã§ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒªã‚½ãƒ¼ã‚¹ã‚’æœ€å¤§é™ã«æ´»ç”¨ã—ã¾ã—ã‚‡ã†ã€‚
Xorbits Inference ã¯ã€GPU ã‚„ CPU ã‚’å«ã‚€ç•°ç¨®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã«åˆ©ç”¨ã—ã€ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚¿ã‚¹ã‚¯ã‚’é«˜é€ŸåŒ–ã—ã¾ã™ã€‚

âš™ï¸ **æŸ”è»Ÿãª API ã¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**: ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ãªç®¡ç†ã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã®ãŸã‚ã«ã€RPCã€
RESTful APIï¼ˆOpenAI API ã¨äº’æ›æ€§ã‚ã‚Šï¼‰ã€CLIã€WebUI ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

ğŸŒ **é…å¸ƒãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ**: Excel ã®åˆ†æ•£å±•é–‹ã‚·ãƒŠãƒªã‚ªã§ã¯ã€è¤‡æ•°ã®ãƒ‡ãƒã‚¤ã‚¹ã‚„ãƒã‚·ãƒ³ã«ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«åˆ†æ•£ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

ğŸ”Œ **ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã®çµ„ã¿è¾¼ã¿çµ±åˆ**: Xorbits Inference ã¯ã€[LangChain](https://python.langchain.com/docs/integrations/providers/xinference)
ã‚„ [LlamaIndex](https://gpt-index.readthedocs.io/en/stable/examples/llm/XinferenceLocalDeployment.html#i-run-pip-install-xinference-all-in-a-terminal-window) ã®ã‚ˆã†ãªäººæ°—ã®ã‚ã‚‹ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨
ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚

## ã¯ã˜ã‚ã«
Xinference ã¯ PyPI ã‹ã‚‰ pip çµŒç”±ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆã‚’é¿ã‘ã‚‹ãŸã‚ã€æ–°ã—ã„ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
$ pip install "xinference"
```
`xinference` ã¯ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã™ã‚‹ãŸã‚ã®åŸºæœ¬çš„ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

#### GGML ã§ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
ggml ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã™ã‚‹ãŸã‚ã«ã¯ã€ä»¥ä¸‹ã®è¿½åŠ ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:
```bash
$ pip install "xinference[ggml]"
```
ç•°ãªã‚‹ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ã—ãŸã„å ´åˆã¯ã€
å¯¾å¿œã™ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
- `baichuan`ã€`wizardlm-v1.0`ã€`vicuna-v1.3`ã€`orca` ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€[llama-cpp-python](https://github.com/abetlen/llama-cpp-python#installation-from-pypi-recommended) ãŒå¿…è¦ã§ã‚ã‚‹ã€‚
- `chatglm` ã¨ `chatglm2` ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€[chatglm-cpp-python](https://github.com/li-plus/chatglm.cpp#getting-started) ãŒå¿…è¦ã§ã‚ã‚‹ã€‚

#### PyTorch ã§ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
PyTorch ã®ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:
```bash
$ pip install "xinference[pytorch]"
```

#### ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ã‚’å«ã‚€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã«ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ãŸã„å ´åˆã¯ã€ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™:
```bash
$ pip install "xinference[all]"
```


### ãƒ‡ãƒ—ãƒ­ã‚¤
Xinference ã¯ã€1 ã¤ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã“ã¨ã‚‚ã€åˆ†æ•£ã‚¯ãƒ©ã‚¹ã‚¿ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

#### ãƒ­ãƒ¼ã‚«ãƒ«
Xinference ã®ãƒ­ãƒ¼ã‚«ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’èµ·å‹•ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™:
```bash
$ xinference
```

#### é…å¸ƒ

Xinference ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ã«å±•é–‹ã™ã‚‹ã«ã¯ã€1 å°ã®ã‚µãƒ¼ãƒãƒ¼ã§ Xinference supervisor ã‚’èµ·å‹•ã—ã€ä»–ã®ã‚µãƒ¼ãƒãƒ¼ã§
Xinference workers ã‚’èµ·å‹•ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã®æ‰‹é †ã«å¾“ã£ã¦ãã ã•ã„:

**supervisor ã®ã‚¹ã‚¿ãƒ¼ãƒˆ**: Xinference supervisor ã‚’å®Ÿè¡Œã™ã‚‹ã‚µãƒ¼ãƒãƒ¼ã§ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™:
```bash
$ xinference-supervisor -H "${supervisor_host}"
```
`${supervisor_host}` ã‚’å®Ÿéš›ã® supervisor ã‚µãƒ¼ãƒã®ãƒ›ã‚¹ãƒˆã«ç½®ãæ›ãˆã¾ã™ã€‚

**Workers ã®ã‚¹ã‚¿ãƒ¼ãƒˆ**: Xinference ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’å®Ÿè¡Œã—ãŸã„ä»–ã®å„ã‚µãƒ¼ãƒãƒ¼ã§ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™:
```bash
$ xinference-worker -e "http://${supervisor_host}:9997"
```

Xinference ãŒèµ·å‹•ã™ã‚‹ã¨ã€CLI ã¾ãŸã¯ Xinference ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®ãŸã‚ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

- ãƒ­ãƒ¼ã‚«ãƒ«é…ç½®ã®å ´åˆã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯ `http://localhost:9997` ã¨ãªã‚Šã¾ã™ã€‚
- ã‚¯ãƒ©ã‚¹ã‚¿å±•é–‹ã®å ´åˆã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯ `http://${supervisor_host}:9997` ã«ãªã‚Šã¾ã™ã€‚
`${supervisor_host}` ã¯ supervisor ãŒç¨¼å‹•ã—ã¦ã„ã‚‹ã‚µãƒ¼ãƒã®ãƒ›ã‚¹ãƒˆåã¾ãŸã¯ IP ã‚¢ãƒ‰ãƒ¬ã‚¹ã§ã™ã€‚

ã¾ãŸã€Xinference ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ã‚¦ã‚§ãƒ– UI ã‚’è¡¨ç¤ºã—ã€ã™ã¹ã¦ã®å†…è”µãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ£ãƒƒãƒˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚
**2 ã¤ã®æœ€å…ˆç«¯ AI ãƒ¢ãƒ‡ãƒ«ã‚’ä¸¦ã¹ã¦ãƒãƒ£ãƒƒãƒˆã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™**ï¼

![web UI](assets/demo.gif)

### Xinference CLI
Xinference ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®ãŸã‚ã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆCLIï¼‰ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¾¿åˆ©ãªã‚³ãƒãƒ³ãƒ‰ã‚’ã„ãã¤ã‹ç´¹ä»‹ã—ã¾ã™:

- ãƒ¢ãƒ‡ãƒ«ã‚’èµ·å‹•ã™ã‚‹ï¼ˆãƒ¢ãƒ‡ãƒ«ã® UID ãŒè¿”ã•ã‚Œã‚‹ï¼‰: `xinference launch`
- å®Ÿè¡Œä¸­ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹: `xinference list`
- å…¨ã¦ã®ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹: `xinference list --all`
- ãƒ¢ãƒ‡ãƒ«ã‚’çµ‚äº†ã™ã‚‹ï¼š ãƒ¢ãƒ‡ãƒ«ã®çµ‚äº†: `xinference terminate --model-uid ${model_uid}`

### Xinference ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
Xinference ã¯ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ãƒ¢ãƒ‡ãƒ«ã‚’ç®¡ç†ã—ã€ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚‚æä¾›ã—ã¦ã„ã¾ã™:

```python
from xinference.client import Client

client = Client("http://localhost:9997")
model_uid = client.launch_model(model_name="chatglm2")
model = client.get_model(model_uid)

chat_history = []
prompt = "What is the largest animal?"
model.chat(
            prompt,
            chat_history,
            generate_config={"max_tokens": 1024}
        )
```

çµæœ:
```json
{
  "id": "chatcmpl-8d76b65a-bad0-42ef-912d-4a0533d90d61",
  "model": "56f69622-1e73-11ee-a3bd-9af9f16816c6",
  "object": "chat.completion",
  "created": 1688919187,
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The largest animal that has been scientifically measured is the blue whale, which has a maximum length of around 23 meters (75 feet) for adult animals and can weigh up to 150,000 pounds (68,000 kg). However, it is important to note that this is just an estimate and that the largest animal known to science may be larger still. Some scientists believe that the largest animals may not have a clear \"size\" in the same way that humans do, as their size can vary depending on the environment and the stage of their life."
      },
      "finish_reason": "None"
    }
  ],
  "usage": {
    "prompt_tokens": -1,
    "completion_tokens": -1,
    "total_tokens": -1
  }
}
```

ãã®ä»–ã®ä¾‹ã¯ [examples](ä¾‹) ã‚’å‚ç…§ã€‚


## å†…è”µãƒ¢ãƒ‡ãƒ«
å†…è”µãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™:
```bash
$ xinference list --all
```


| Name             | Language      | Ability                |
|------------------|---------------|------------------------|
| baichuan         | ['en', 'zh']  | ['embed', 'generate']  |
| baichuan-chat    | ['en', 'zh']  | ['embed', 'chat']      |
| chatglm          | ['en', 'zh']  | ['embed', 'chat']      |
| chatglm2         | ['en', 'zh']  | ['embed', 'chat']      |
| chatglm2-32k     | ['en', 'zh']  | ['embed', 'chat']      |
| falcon           | ['en']        | ['embed', 'generate']  |
| falcon-instruct  | ['en']        | ['embed', 'chat']      |
| gpt-2            | ['en']        | ['generate']           |
| internlm         | ['en', 'zh']  | ['embed', 'generate']  |
| internlm-chat    | ['en', 'zh']  | ['embed', 'chat']      |
| internlm-chat-8k | ['en', 'zh']  | ['embed', 'chat']      |
| llama-2          | ['en']        | ['embed', 'generate']  |
| llama-2-chat     | ['en']        | ['embed', 'chat']      |
| opt              | ['en']        | ['embed', 'generate']  |
| orca             | ['en']        | ['embed', 'chat']      |
| qwen-chat        | ['en', 'zh']  | ['embed', 'chat']      |
| starchat-beta    | ['en']        | ['embed', 'chat']      |
| starcoder        | ['en']        | ['generate']           |
| starcoderplus    | ['en']        | ['embed', 'generate']  |
| vicuna-v1.3      | ['en']        | ['embed', 'chat']      |
| vicuna-v1.5      | ['en']        | ['embed', 'chat']      |
| vicuna-v1.5-16k  | ['en']        | ['embed', 'chat']      |
| wizardlm-v1.0    | ['en']        | ['embed', 'chat']      |
| wizardmath-v1.0  | ['en']        | ['embed', 'chat']      |

**æ³¨**:
- Xinference ã¯è‡ªå‹•çš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ `${USER}/.xinference/cache` ã®ä¸‹ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚
- Foundation ãƒ¢ãƒ‡ãƒ«ã¯ `generate` ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ã¿ã‚’æä¾›ã™ã‚‹ã€‚
- RLHF ã¨ SFT ã®ãƒ¢ãƒ‡ãƒ«ã¯ `generate` ã¨ `chat` ã®ä¸¡æ–¹ã‚’æä¾›ã™ã‚‹ã€‚
- Apple Metal GPU ã‚’ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€q4_0 ã¨ q4_1 ã®é‡å­åŒ–æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚
- `llama-2-chat` 70B ggmlv3 ãƒ¢ãƒ‡ãƒ«ã¯ç¾åœ¨ q4_0 é‡å­åŒ–ã—ã‹ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ã€‚


## Pytorch ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

æœ€è¿‘ Pytorch ãŒçµ±åˆã•ã‚Œã¾ã—ãŸã€‚ä½¿ç”¨ã‚·ãƒŠãƒªã‚ªã‚’ä»¥ä¸‹ã«èª¬æ˜ã—ã¾ã™:

### ã‚µãƒãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«
- åŸºç¤ãƒ¢ãƒ‡ãƒ«: baichuanï¼ˆ7Bã€13Bï¼‰ã€‚
- SFT ãƒ¢ãƒ‡ãƒ«: baichuan-chatï¼ˆ13Bï¼‰ã€vicuna-v1.3ï¼ˆ7Bã€13Bã€33Bï¼‰ã€‚

### ã‚µãƒãƒ¼ãƒˆãƒ‡ãƒã‚¤ã‚¹
- CUDAï¼š Linux ã¨ Windows ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ `cuda` ãƒ‡ãƒã‚¤ã‚¹ãŒä½¿ç”¨ã•ã‚Œã‚‹ã€‚
- MPSï¼š Mac M1/M2 ãƒ‡ãƒã‚¤ã‚¹ã§ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ `mps` ãƒ‡ãƒã‚¤ã‚¹ãŒä½¿ç”¨ã•ã‚Œã‚‹ã€‚
- CPUï¼š `cpu` ãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã¯æ¨å¥¨ã•ã‚Œãªã„ã€‚å¤šãã®ãƒ¡ãƒ¢ãƒªã‚’æ¶ˆè²»ã—ã€æ¨è«–é€Ÿåº¦ãŒéå¸¸ã«é…ããªã‚‹ã‹ã‚‰ã§ã™ã€‚

### é‡å­åŒ–ãƒ¡ã‚½ãƒƒãƒ‰
- `none`: é‡å­åŒ–ã‚’è¡Œã‚ãªã„ã“ã¨ã‚’ç¤ºã™ã€‚
- `8-bit`: 8 ãƒ“ãƒƒãƒˆé‡å­åŒ–ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
- `4-bit`: 4 ãƒ“ãƒƒãƒˆé‡å­åŒ–ã‚’ä½¿ç”¨ã™ã‚‹ã€‚æ³¨æ„ï¼š4ãƒ“ãƒƒãƒˆé‡å­åŒ–ã¯ Linux ã‚·ã‚¹ãƒ†ãƒ ã¨ CUDA ãƒ‡ãƒã‚¤ã‚¹ã§ã®ã¿ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚

### ãã®ä»–ã®å‘½ä»¤
- MacOSã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€baichuan-chat ãƒ¢ãƒ‡ãƒ«ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ãŠã‚‰ãšã€baichuan ãƒ¢ãƒ‡ãƒ«ã¯ 8 ãƒ“ãƒƒãƒˆé‡å­åŒ–ã‚’ä½¿ç”¨ã§ããªã„

### ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹

ä»¥ä¸‹ã®è¡¨ã¯ã€ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¨å¯¾å¿œãƒ‡ãƒã‚¤ã‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚

| Name          | Size (B) | OS    | No quantization (MB) | Quantization 8-bit (MB) | Quantization 4-bit (MB) |
|---------------|----------|-------|----------------------|-------------------------|-------------------------|
| baichuan-chat | 13       | linux | not currently tested | 13275                   | 7263                    |
| baichuan-chat | 13       | macos | not supported        | not supported           | not supported           |
| vicuna-v1.3   | 7        | linux | 12884                | 6708                    | 3620                    |
| vicuna-v1.3   | 7        | macos | 12916                | 565                     | not supported           |
| baichuan      | 7        | linux | 13480                | 7304                    | 4216                    |
| baichuan      | 7        | macos | 13480                | not supported           | not supported           |



## ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—
Xinference ã¯ç¾åœ¨æ´»ç™ºã«é–‹ç™ºä¸­ã§ã™ã€‚ä»Šå¾Œæ•°é€±é–“ã®é–‹ç™ºäºˆå®šãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™:

### Langchain ã¨ LlamaIndex çµ±åˆ
Xinference ãŒã‚ã‚Œã°ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã“ã‚Œã‚‰ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã€LLM ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒã‚ˆã‚Šç°¡å˜ã«ãªã‚Šã¾ã™ã€‚
