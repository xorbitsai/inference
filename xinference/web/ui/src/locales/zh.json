{
  "menu": {
    "launchModel": "启动模型",
    "runningModels": "运行模型",
    "registerModel": "注册模型",
    "clusterInfo": "集群信息",
    "contactUs": "联系我们"
  },

  "model": {
    "languageModels": "语言模型",
    "embeddingModels": "嵌入模型",
    "rerankModels": "重排序模型",
    "imageModels": "图像模型",
    "audioModels": "音频模型",
    "videoModels": "视频模型",
    "customModels": "自定义模型",
    "flexibleModels": "灵活模型"
  },

  "launchModel": {
    "modelAbility": "模型能力",
    "generate": "生成",
    "chat": "聊天",
    "vision": "视觉聊天",
    "status": "状态",
    "cached": "已缓存",
    "manageCachedModels": "管理缓存模型",
    "favorite": "收藏",
    "unfavorite": "取消收藏",
    "search": "搜索模型名称和描述",
    "searchModelType": "搜索 {{modelType}} 相关的模型名称",
    "searchInstruction": "输入 {{hotkey}} 进行搜索",
    "clickToLaunchModel": "点击鼠标以启动模型",
    "dimensions": "维度",
    "maxTokens": "最大 token 数",
    "edit": "编辑",
    "delete": "删除",
    "contextLength": "上下文长度",
    "chatModel": "聊天模型",
    "generateModel": "生成模型",
    "otherModel": "其他模型",
    "confirmDeleteCustomModel": "您确定要删除这个自定义模型吗？此操作无法恢复。",
    "lastConfig": "最后配置",
    "commandLineParsing": "解析命令行参数",
    "copyToCommandLine": "复制为命令行指令",
    "modelEngine": "模型引擎",
    "modelFormat": "模型格式",
    "modelSize": "模型大小",
    "quantization": "量化",
    "nGPU": "GPU 数量",
    "nGPUPerWorker": "每个 Worker 上的 GPU 数量",
    "nGpuLayers": "GPU 层数",
    "replica": "副本",
    "optionalConfigurations": "可选配置",
    "modelUID.optional": "(可选) 模型 UID，默认是模型名称",
    "requestLimits.optional": "(可选) 请求限制，模型的请求限制数，默认值为无",
    "workerIp.optional": "(可选) 工作节点 IP，在分布式场景中指定模型所在的工作节点 IP",
    "workerIp": "工作节点 IP，在分布式场景中指定模型所在的工作节点 IP",
    "workerCount.optional": "(可选) Worker 数量",
    "GPUIdx.optional": "(可选) GPU 索引，指定模型所在的 GPU 索引",
    "GPUIdx": "GPU 索引，指定模型所在的 GPU 索引",
    "downloadHub.optional": "(可选) 下载中心",
    "modelPath.optional": "(可选) 模型路径，对于 PyTorch，提供模型目录；对于 GGML/GGUF，提供模型文件路径。",
    "GGUFQuantization.optional": "(可选) GGUF量化格式，对Transformer部分进行量化。",
    "GGUFModelPath.optional": "(可选) GGUF模型路径，应为以 .gguf 结尾的文件。",
    "CPUOffload": "CPU卸载",
    "CPUOffload.tip": "将模型卸载到CPU。当资源有限或使用GGUF选项时，建议启用此功能。",
    "loraConfig": "Lora 配置",
    "loraModelConfig": "Lora 模型配置",
    "additionalParametersForInferenceEngine": "传递给推理引擎的附加参数",
    "enterIntegerGreaterThanZero": "请输入大于 0 的整数。",
    "enterCommaSeparatedNumbers": "请输入以逗号分隔的数字数据，例如：0,1,2",
    "device": "设备",
    "loraLoadKwargsForImageModel": "图像模型的 Lora 加载参数",
    "loraFuseKwargsForImageModel": "图像模型的 Lora 融合参数",
    "launch": "启动",
    "goBack": "返回",
    "copyJson": "复制 JSON",
    "cancel": "取消",
    "confirm": "确定",
    "placeholderTip": "请输入",
    "fillCompleteParametersBeforeAdding": "请在添加之前填写完整的参数！",
    "model_format": "模型格式",
    "model_size_in_billions": "模型大小（以十亿为单位）",
    "quantizations": "量化方式",
    "real_path": "真实路径",
    "path": "路径",
    "ipAddress": "IP 地址",
    "operation": "操作",
    "copyRealPath": "复制真实路径",
    "copyPath": "复制路径",
    "noCacheForNow": "当前没有缓存！",
    "confirmDeleteCacheFiles": "确认删除缓存文件吗？此操作无法恢复。",
    "commandLineTip": "请确定模型名称是否一致。",
    "featured": "推荐",
    "all": "全部"
  },

  "runningModels": {
    "name": "名称",
    "address": "地址",
    "gpuIndexes": "GPU 索引",
    "size": "大小",
    "quantization": "量化",
    "replica": "副本",
    "actions": "操作",
    "noRunningModels": "没有运行中的模型",
    "noRunningModelsMatches": "没有匹配的运行模型"
  },

  "registerModel": {
    "modelName": "模型名称",
    "modelDescription": "模型描述（可选）",
    "contextLength": "上下文长度",
    "dimensions": "维度",
    "maxTokens": "最大 token 数",
    "modelPath": "模型路径",
    "modelLanguages": "模型语言",
    "languages": "语言",
    "multilingual": "多语言",
    "modelAbilities": "模型能力",
    "modelFamily": "模型系列",
    "chatTemplate": "聊天模板",
    "test": "测试",
    "testResult": "测试结果",
    "noTestResults": "没有测试结果...",
    "stopTokenIds": "停止token ID",
    "stop": "停止",
    "launcher": "启动器",
    "launcherArguments": "启动器参数（可选）",
    "edit": "编辑",
    "cancel": "取消",
    "registerModel": "注册模型",
    "messagesExample": "消息示例",
    "JSONFormat": "JSON 格式",
    "modelSpecs": "模型规格",
    "modelSizeBillions": "模型大小（以十亿为单位）",
    "quantization": "量化",
    "quantizationOptional": "量化（可选）",
    "delete": "删除",
    "controlnet": "控制网",
    "more": "更多",
    "modelFormat": "模型格式",
    "enterNumberGreaterThanZero": "请输入大于 0 的数字。",
    "carefulQuantizationForModelRegistration": "对于 GPTQ/AWQ/FP8/MLX 模型，请小心填写与您要注册的模型对应的量化方式。",
    "quantizationCannotBeEmpty": "量化方式不能为空。",
    "enterInteger": "请输入一个整数。",
    "enterIntegerGreaterThanZero": "请输入大于 0 的整数。",
    "showCustomJsonConfig": "显示由 API 使用的自定义 JSON 配置",
    "packUp": "收起",
    "unfold": "展开",
    "copyAll": "复制全部",
    "alphanumericWithHyphensUnderscores": "字母数字字符，连字符和下划线应正确放置。不能与任何内置模型名称匹配。",
    "chooseBuiltInOrCustomModel": "您可以选择内置模型或输入自定义模型。",
    "chooseOnlyBuiltInModel": "您只能从内置模型中选择。",
    "provideModelDirectoryPath": "提供模型目录路径。",
    "provideModelLauncher": "提供模型启动器。",
    "jsonArgumentsForLauncher": "一个 JSON 格式的字典，表示传递给启动器的参数。",
    "provideModelDirectoryOrFilePath": "对于 PyTorch，提供模型目录。对于 GGUF，提供模型文件路径。",
    "ensureChatTemplatePassesTest": "请确保通过点击右侧的测试按钮，使此聊天模板通过测试。请注意，此测试可能无法涵盖所有情况，只会用于最基本的情况。",
    "testFailurePreventsChatWorking": "请注意，未通过测试可能会导致聊天无法正常工作。",
    "stopControlForChatModels": "整数类型，用于控制聊天模型的停止。",
    "stopControlStringForChatModels": "字符串类型，用于控制聊天模型的停止。",
    "enterJsonFormattedDictionary": "请输入 JSON 格式的字典。"
  },

  "clusterInfo": {
    "supervisor": "主管",
    "workers": "工作节点",
    "workerDetails": "工作节点详情",
    "count": "数量",
    "cpuInfo": "CPU 信息",
    "usage": "使用率：",
    "total": "总计",
    "cpuMemoryInfo": "CPU 内存信息",
    "version": "版本",
    "release": "发布：",
    "commit": "提交：",
    "gpuInfo": "GPU 信息",
    "gpuMemoryInfo": "GPU 内存信息",
    "address": "地址",
    "item": "项",
    "value": "值",
    "nodeType": "节点类型",
    "cpuUsage": "CPU 使用率",
    "cpuTotal": "CPU 总数",
    "memUsage": "内存使用率",
    "memTotal": "内存总量",
    "gpuCount": "GPU 数量",
    "gpuMemUsage": "GPU 内存使用率",
    "gpuMemTotal": "GPU 内存总量",
    "worker": "工作节点"
  },

  "components": {
    "copySuccess": "已复制到剪贴板！"
  }
}
