export const llmAllDataKey = [
  'model_uid',
  'model_name',
  'model_type',
  'model_engine',
  'model_format',
  'model_size_in_billions',
  'quantization',
  'n_worker',
  'n_gpu',
  'n_gpu_layers',
  'replica',
  'request_limits',
  'worker_ip',
  'gpu_idx',
  'download_hub',
  'model_path',
  'reasoning_content',
  'gguf_quantization',
  'gguf_model_path',
  'lightning_version',
  'lightning_model_path',
  'cpu_offload',
  'peft_model_config',
  'quantization_config',
  'enable_thinking',
  'multimodal_projector',
  'enable_virtual_env',
  'virtual_env_packages',
  'envs',
]

export const additionalParameterTipList = {
  'transformers': ['torch_dtype', 'device', 'enable_flash_attn'],
  'llama.cpp': ['n_ctx', 'use_mmap', 'use_mlock'],
  'vllm': [
    'block_size',
    'gpu_memory_utilization',
    'max_num_seqs',
    'max_model_len',
    'guided_decoding_backend',
    'scheduling_policy',
    'tensor_parallel_size',
    'pipeline_parallel_size',
    'enable_prefix_caching',
    'enable_chunked_prefill',
    'enforce_eager',
    'cpu_offload_gb',
    'disable_custom_all_reduce',
    'limit_mm_per_prompt',
    'model_quantization',
    'mm_processor_kwargs',
    'min_pixels',
    'max_pixels',
  ],
  'sglang': [
    'mem_fraction_static',
    'attention_reduce_in_fp32',
    'tp_size',
    'dp_size',
    'chunked_prefill_size',
    'cpu_offload_gb',
    'enable_dp_attention',
    'enable_ep_moe',
  ],
  'mlx': ['cache_limit_gb', 'max_kv_size'],
}

export const quantizationParametersTipList = [
  'load_in_8bit',
  'load_in_4bit',
  'llm_int8_threshold',
  'llm_int8_skip_modules',
  'llm_int8_enable_fp32_cpu_offload',
  'llm_int8_has_fp16_weight',
  'bnb_4bit_compute_dtype',
  'bnb_4bit_quant_type',
  'bnb_4bit_use_double_quant',
  'bnb_4bit_quant_storage',
]

export const featureModels = [
  {
    type: 'llm',
    feature_models: [
      'Deepseek-V3.1',
      'gpt-oss',
      'qwen3',
      'Ernie4.5',
      'deepseek-r1-0528',
      'deepseek-r1-0528-qwen3',
      'qwen2.5-vl-instruct',
      'glm-4.5',
      'QwQ-32B',
      'gemma-3-it',
    ],
  },
  {
    type: 'embedding',
    feature_models: [
      'Qwen3-Embedding-0.6B',
      'Qwen3-Embedding-4B',
      'Qwen3-Embedding-8B',
      'bge-large-zh-v1.5',
      'bge-large-en-v1.5',
      'bge-m3',
      'gte-Qwen2',
      'jina-embeddings-v3',
    ],
  },
  {
    type: 'rerank',
    feature_models: [],
  },
  {
    type: 'image',
    feature_models: [
      'Qwen-Image',
      'Qwen-Image-Edit-2509',
      'FLUX.1-dev',
      'FLUX.1-Kontext-dev',
      'FLUX.1-schnell',
      'sd3.5-large',
      'HunyuanDiT-v1.2',
      'cogview4',
      'sd3.5-medium',
    ],
  },
  {
    type: 'audio',
    feature_models: [
      'IndexTTS2',
      'CosyVoice2-0.5B',
      'FishSpeech-1.5',
      'F5-TTS',
      'ChatTTS',
      'SenseVoiceSmall',
      'whisper-large-v3',
    ],
  },
  {
    type: 'video',
    feature_models: [],
  },
]
