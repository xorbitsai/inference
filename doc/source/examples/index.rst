.. _examples_index:

========
Examples
========

.. toctree::
   :maxdepth: 2
   :hidden:

   ai_podcast
   chatbot
   gradio_chatinterface
   pdf_chatbot

Here you can find examples and resources to learn about how to use Xinference.

Examples
========

End-to-end examples of using Xinference for various tasks:

* `Voice Conversations with AI Agents on M2 Max <ai_podcast.html>`_

* `Interacting with LLM Models: A Command-Line Example <chatbot.html>`_

* `Interacting with LLM Models: A Gradio ChatInterface Example <gradio_chatinterface.html>`_

* `PDF Chatbot with Local LLM and Embeddings <pdf_chatbot.html>`_ 

If you come across other examples in your own workflows we encourage you to contribute a `PR <https://github.com/xorbitsai/inference/pulls>`_!


Tutorials
=========

The following tutorials cover the basics of using Xinference in different scenarios:

* `Build a QA Application with Xinference and LangChain <https://github.com/RayJi01/Xprobe_inference/blob/main/examples/LangChain_QA.ipynb>`_

* `Using Xinference local LLMs within LlamaIndex <https://gpt-index.readthedocs.io/en/stable/examples/llm/XinferenceLocalDeployment.html>`_

* `[Chinese] 如何让 Chatbox 接入开源大模型，实现免费聊天 <https://twitter.com/benn_huang/status/1701420060240490785>`_

* `[Chinese] 摆脱 OpenAI 依赖，8 分钟教你用开源生态构建全栈 AI 应用 <https://mp.weixin.qq.com/s/cXBC0dikldNiGwOwPuJfUQ>`_

* `[Chinese] 使用全套开源工具构建 LLM 应用实战 <https://mp.weixin.qq.com/s/regqYkF0cNDQIdOkOeyeXQ>`_


Third-Party Library Integrations
================================

Xinference is designed to seamlessly integrate and deploy open-sourced AI models, so we want to incorporate support for mainstream toolkits
in the AI landscape. Xinference can be used with the following third-party libraries:

* LangChain `Text Embedding Models <https://python.langchain.com/docs/integrations/text_embedding/xinference>`_ and `LLMs <https://python.langchain.com/docs/integrations/llms/xinference>`_

* `LlamaIndex Xinference LLM <https://docs.llamaindex.ai/en/stable/api_reference/llms/xinference.html>`_
