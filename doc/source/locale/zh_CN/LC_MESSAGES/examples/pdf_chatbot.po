# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Xorbits Inc.
# This file is distributed under the same license as the Xinference package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Xinference \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-11-01 10:48+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"

#: ../../source/examples/pdf_chatbot.rst:5
msgid "Example: PDF ChatbotğŸ“š"
msgstr "ç¤ºä¾‹ï¼šPDF èŠå¤©æœºå™¨äººğŸ“š"

#: ../../source/examples/pdf_chatbot.rst:7
msgid "**Description**:"
msgstr "**æè¿°**ï¼š"

#: ../../source/examples/pdf_chatbot.rst:9
msgid ""
"This example showcases how to build a PDF chatbot with local LLM and "
"Embedding models"
msgstr ""
"è¿™ä¸ªä¾‹å­å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨æœ¬åœ° LLM å’Œ embedding æ¨¡å‹æ„å»ºPDFèŠå¤©æœºå™¨äººã€‚"

#: ../../source/examples/pdf_chatbot.rst:11
msgid "**Used Technology**:"
msgstr "**æ¶‰åŠæŠ€æœ¯**ï¼š"

#: ../../source/examples/pdf_chatbot.rst:13
msgid ""
"@ `Xinference <https://github.com/xorbitsai/inference>`_ as a LLM model "
"hosting service"
msgstr "@ `Xinference <https://github.com/xorbitsai/inference>`_ ä½œä¸ºLLMæ¨¡å‹æ‰˜ç®¡æœåŠ¡"

#: ../../source/examples/pdf_chatbot.rst:15
msgid ""
"@ `LlamaIndex <https://github.com/run-llama/llama_index>`_ for "
"orchestrating the entire RAG pipeline"
msgstr "@ `LlamaIndex <https://github.com/run-llama/llama_index>`_ ç”¨äºç¼–æ’æ•´ä¸ªRAGç®¡é“"

#: ../../source/examples/pdf_chatbot.rst:17
msgid "@ `Streamlit <https://streamlit.io/>`_ for interactive UI"
msgstr "@ `Streamlit <https://streamlit.io/>`_ ç”¨äºäº¤äº’å¼ç”¨æˆ·ç•Œé¢"

#: ../../source/examples/pdf_chatbot.rst:19
msgid "**Detailed Explanation on the Demo Functionality** :"
msgstr "**å…³äºæ¼”ç¤ºåŠŸèƒ½çš„è¯¦ç»†è¯´æ˜**ï¼š"

#: ../../source/examples/pdf_chatbot.rst:21
msgid ""
"Crafted a Dockerfile to simplify the process and ensure easy "
"reproducibility."
msgstr "åˆ¶ä½œäº†ä¸€ä¸ªDockerfileï¼Œé€šè¿‡ docker ç®€åŒ–äº†éƒ¨ç½²æµç¨‹å¹¶ç¡®ä¿æ˜“äºå¤ç°ã€‚"

#: ../../source/examples/pdf_chatbot.rst:23
msgid "Set up models with Xinference and expose two ports for accessing them."
msgstr "ä½¿ç”¨ Xinference æ‹‰èµ· LLM å’Œ embedding æ¨¡å‹ï¼Œå¹¶æš´éœ²ä¸¤ä¸ªç«¯å£ä»¥è®¿é—®å®ƒä»¬ã€‚"

#: ../../source/examples/pdf_chatbot.rst:25
msgid ""
"Leverage Streamlit for seamless file uploads and interactive "
"communication with the chat engine."
msgstr "åˆ©ç”¨ Streamlit å®ç°æ— ç¼æ–‡ä»¶ä¸Šä¼ å’Œä¸èŠå¤©å¼•æ“çš„äº¤äº’é€šä¿¡ã€‚"

#: ../../source/examples/pdf_chatbot.rst:27
msgid "5x faster doc embedding than OpenAI's API."
msgstr "æ–‡æ¡£ embedding é€Ÿåº¦æ¯” OpenAI çš„ APIå¿«5å€ã€‚"

#: ../../source/examples/pdf_chatbot.rst:29
msgid ""
"Leveraging the power of GGML to offload models to the GPU, ensuring swift"
" acceleration. Less long waits for returns."
msgstr "åˆ©ç”¨ GGML çš„å¼ºå¤§åŠŸèƒ½å°†æ¨¡å‹ç½®äºGPUä¸Šè¿è¡Œï¼Œç¡®ä¿åŠ é€Ÿã€å‡å°‘ç­‰å¾…è¿”å›çš„æ—¶é—´ã€‚"

#: ../../source/examples/pdf_chatbot.rst:31
msgid "**Source Code** :"
msgstr "**æºä»£ç **ï¼š"

#: ../../source/examples/pdf_chatbot.rst:32
msgid ""
"`PDF Chatbot <https://github.com/onesuper/PDF-Chatbot-Local-LLM-"
"Embeddings>`_"
msgstr ""

