# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Xorbits Inc.
# This file is distributed under the same license as the Xinference package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Xinference \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-12-25 17:11+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:5
msgid "Example: LangChain Streamlit Doc ChatğŸ“„"
msgstr "ç¤ºä¾‹ï¼šLangChain Streamlit æ–‡æ¡£èŠå¤©ğŸ“„"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:7
msgid "**Description**:"
msgstr "**æè¿°**ï¼š"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:9
msgid ""
"This Streamlit-based application demonstrates a AI chatbot powered by "
"local LLM and embedding models"
msgstr "è¿™ä¸ªåŸºäº Streamlit çš„åº”ç”¨æ¼”ç¤ºäº†ç”±æœ¬åœ° LLM å’Œ embedding æ¨¡å‹æä¾›æ”¯æŒçš„ AI èŠå¤©æœºå™¨äººã€‚"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:11
msgid "**Used Technology**:"
msgstr "**æ¶‰åŠæŠ€æœ¯**ï¼š"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:13
msgid ""
"@ `Xinference <https://github.com/xorbitsai/inference>`_: as the LLM and "
"embedding model hosting service"
msgstr "@ `Xinference <https://github.com/xorbitsai/inference>`_ï¼šä½œä¸º LLM å’Œ embedding æ¨¡å‹æ‰˜ç®¡æœåŠ¡"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:15
msgid ""
"@ `LangChain <https://github.com/run-llama/llama_index>`_: orchestrates "
"the entire document processing and query answering pipeline"
msgstr "@ `LangChain <https://github.com/run-llama/llama_index>`_ï¼šç¼–æ’æ•´ä¸ªæ–‡æ¡£å¤„ç†å’ŒæŸ¥è¯¢å›ç­”çš„ç®¡é“"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:17
msgid "@ `Streamlit <https://streamlit.io/>`_: for interactive user interface"
msgstr "@ `Streamlit <https://streamlit.io/>`_ï¼šç”¨äºäº¤äº’å¼ç”¨æˆ·ç•Œé¢"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:19
msgid "**Detailed Explanation on the Demo Functionality** :"
msgstr "**å…³äºæ¼”ç¤ºåŠŸèƒ½çš„è¯¦ç»†è¯´æ˜**ï¼š"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:21
msgid "Streamlit UI for uploading text files, enhancing user interaction."
msgstr "Streamlit ç”¨æˆ·ç•Œé¢ï¼Œç”¨äºä¸Šä¼ æ–‡æœ¬æ–‡ä»¶ï¼Œæå‡ç”¨æˆ·äº¤äº’ã€‚"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:23
msgid ""
"Texts are split into chunks and embedded using Xinference for efficient "
"processing."
msgstr "æ–‡æœ¬è¢«åˆ†å‰²æˆå—ï¼Œå¹¶ä½¿ç”¨ Xinference è¿›è¡Œ embed æ“ä½œï¼Œä»¥å®ç°é«˜æ•ˆçš„å¤„ç†ã€‚"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:25
msgid ""
"Executes similarity searches on embedded texts to pinpoint relevant "
"sections for user queries."
msgstr "å¯¹åµŒå…¥çš„æ–‡æœ¬æ‰§è¡Œç›¸ä¼¼æ€§æœç´¢ï¼Œä»¥ç²¾ç¡®å®šä½ç”¨æˆ·æŸ¥è¯¢çš„ç›¸å…³éƒ¨åˆ†ã€‚"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:27
msgid "Utilizes a structured prompt template for focused LLM interactions."
msgstr "åˆ©ç”¨ç»“æ„åŒ–çš„æç¤ºè¯æ¨¡æ¿ä¸ LLM æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:29
msgid ""
"Xinference's LLM processes queries within the context of relevant "
"document parts, providing accurate responses."
msgstr ""
"Xinference çš„ LLM åœ¨ç›¸å…³æ–‡æ¡£éƒ¨åˆ†çš„ä¸Šä¸‹æ–‡ä¸­å¤„ç†æŸ¥è¯¢ï¼Œæä¾›å‡†ç¡®çš„å“åº”ã€‚"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:31
msgid ""
"The system facilitates effective and context-sensitive document "
"exploration, aiding users in information retrieval."
msgstr ""
"è¯¥ç³»ç»Ÿå®ç°äº†æœ‰æ•ˆçš„ã€ä¸Šä¸‹æ–‡æ•æ„Ÿçš„æ–‡æ¡£æœç´¢ï¼Œå¸®åŠ©ç”¨æˆ·è¿›è¡Œé«˜æ•ˆä¿¡æ¯æ£€ç´¢ã€‚"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:33
msgid "**Source Code** :"
msgstr "**æºä»£ç **ï¼š"

#: ../../source/examples/langchain_streamlit_doc_chat.rst:34
msgid ""
"`LangChain Streamlit Doc Chat "
"<https://github.com/xorbitsai/inference/blob/main/examples/LangChain_Streamlit_Doc_Chat.py>`_"
msgstr ""

