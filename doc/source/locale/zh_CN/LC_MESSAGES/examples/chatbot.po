# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Xorbits Inc.
# This file is distributed under the same license as the Xinference package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Xinference \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-11-01 10:48+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"

#: ../../source/examples/chatbot.rst:5
msgid "Example: CLI chatbot ğŸ¤–ï¸"
msgstr "ç¤ºä¾‹ï¼šå‘½ä»¤è¡ŒèŠå¤©æœºå™¨äºº ğŸ¤–ï¸"

#: ../../source/examples/chatbot.rst:7
msgid "**Description**:"
msgstr "**æè¿°**ï¼š"

#: ../../source/examples/chatbot.rst:9
msgid ""
"Demonstrate how to interact with Xinference to play with LLM chat "
"functionality with an AI agent in command lineğŸ’»"
msgstr ""
"æ¼”ç¤ºå¦‚ä½•ä¸ Xinference äº¤äº’ï¼Œåœ¨å‘½ä»¤è¡Œä¸­åŸºäº LLM çš„èŠå¤©åŠŸèƒ½ä¸ AI ä»£ç†äº’åŠ¨ã€‚ğŸ’»"

#: ../../source/examples/chatbot.rst:11
msgid "**Used Technology**:"
msgstr "**æ¶‰åŠæŠ€æœ¯**ï¼š"

#: ../../source/examples/chatbot.rst:13
msgid ""
"@ `ggerganov <https://twitter.com/ggerganov>`_ 's `ggml "
"<https://github.com/ggerganov/ggml>`_"
msgstr ""
"@ `ggerganov <https://twitter.com/ggerganov>`_ `ggml <https://github.com/ggerganov/ggml>`_"

#: ../../source/examples/chatbot.rst:15
msgid "@ `Xinference <https://github.com/xorbitsai/inference>`_ as a launcher"
msgstr ""
"@ `Xinference <https://github.com/xorbitsai/inference>`_ ä½œä¸ºå¹³å°"

#: ../../source/examples/chatbot.rst:17
msgid ""
"@ All LLaMA and Chatglm models supported by `Xorbitsio inference "
"<https://github.com/xorbitsai/inference>`_"
msgstr ""
"ç”± `Xinference æ¨ç† <https://github.com/xorbitsai/inference>`_ æ”¯æŒçš„æ‰€æœ‰ LLaMA å’Œ Chatglm æ¨¡å‹"

#: ../../source/examples/chatbot.rst:19
msgid "**Detailed Explanation on the Demo Functionality** :"
msgstr "**å…³äºæ¼”ç¤ºåŠŸèƒ½çš„è¯¦ç»†è¯´æ˜**ï¼š"

#: ../../source/examples/chatbot.rst:21
msgid ""
"Take the user command line input in the terminal and grab the required "
"parameters for model launching."
msgstr ""
"åœ¨ç»ˆç«¯ä¸­æ¥å—ç”¨æˆ·çš„å‘½ä»¤è¡Œè¾“å…¥ï¼Œå¹¶è·å–å¯åŠ¨æ¨¡å‹æ‰€éœ€çš„å‚æ•°ã€‚"

#: ../../source/examples/chatbot.rst:23
msgid ""
"Launch the Xinference frameworks and automatically deploy the model user "
"demanded into the cluster."
msgstr ""
"å¯åŠ¨ Xinference æ¡†æ¶ï¼Œå¹¶è‡ªåŠ¨å°†ç”¨æˆ·éœ€æ±‚çš„æ¨¡å‹éƒ¨ç½²åˆ°é›†ç¾¤ä¸­ã€‚"

#: ../../source/examples/chatbot.rst:25
msgid "Initialize an empty chat history to store all the context in the chatroom."
msgstr ""
"åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„èŠå¤©å†å²ï¼Œä»¥å­˜å‚¨èŠå¤©å®¤ä¸­çš„æ‰€æœ‰ä¸Šä¸‹æ–‡ã€‚"

#: ../../source/examples/chatbot.rst:27
msgid ""
"Recursively ask for user's input as prompt and let the model to generate "
"response based on the prompt and the chat history. Show the Output of the"
" response in the terminal."
msgstr ""
"é€’å½’åœ°è¯·æ±‚ç”¨æˆ·çš„è¾“å…¥ä½œä¸ºæç¤ºè¯ï¼Œè®©æ¨¡å‹åŸºäºæç¤ºè¯å’ŒèŠå¤©å†å²ç”Ÿæˆå“åº”ã€‚åœ¨ç»ˆç«¯ä¸­æ˜¾ç¤ºå“åº”çš„è¾“å‡ºã€‚"

#: ../../source/examples/chatbot.rst:30
msgid ""
"Store the user's input and agent's response into the chat history as "
"context for the upcoming rounds."
msgstr ""
"å°†ç”¨æˆ·çš„è¾“å…¥å’Œä»£ç†çš„å“åº”å­˜å‚¨åˆ°èŠå¤©å†å²ä¸­ï¼Œä½œä¸ºå³å°†åˆ°æ¥çš„å¯¹è¯è½®æ¬¡çš„ä¸Šä¸‹æ–‡ã€‚"

#: ../../source/examples/chatbot.rst:32
msgid "**Source Code** :"
msgstr "**æºä»£ç **ï¼š"

#: ../../source/examples/chatbot.rst:33
msgid ""
"`chat "
"<https://github.com/RayJi01/Xprobe_inference/blob/main/examples/chat.py>`_"
msgstr ""
