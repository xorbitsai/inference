# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Xorbits Inc.
# This file is distributed under the same license as the Xinference package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2024.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Xinference \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-12-25 18:32+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.14.0\n"

#: ../../source/models/model_abilities/image.rst:5
msgid "Images"
msgstr "图像"

#: ../../source/models/model_abilities/image.rst:7
msgid "Learn how to generate images with Xinference."
msgstr "学习如何使用 Xinference 生成图像。"

#: ../../source/models/model_abilities/image.rst:11
msgid "Introduction"
msgstr "介绍"

#: ../../source/models/model_abilities/image.rst:14
msgid "The Images API provides two methods for interacting with images:"
msgstr "Images API提供了两种与图像交互的方法："

#: ../../source/models/model_abilities/image.rst:17
msgid ""
"The Text-to-image endpoint create images from scratch based on a text "
"prompt."
msgstr "文生图端点根据文本从零开始创建图像。"

#: ../../source/models/model_abilities/image.rst:18
msgid ""
"The Image-to-image endpoint allows you to generate a variation of a given"
" image."
msgstr "图生图端点允许您生成给定图像的变体。"

#: ../../source/models/model_abilities/image.rst:25
msgid "API ENDPOINT"
msgstr "API 端点"

#: ../../source/models/model_abilities/image.rst:26
msgid "OpenAI-compatible ENDPOINT"
msgstr "OpenAI 兼容端点"

#: ../../source/models/model_abilities/image.rst:28
msgid "Text-to-Image API"
msgstr ""

#: ../../source/models/model_abilities/image.rst:29
msgid "/v1/images/generations"
msgstr ""

#: ../../source/models/model_abilities/image.rst:31
msgid "Image-to-image API"
msgstr ""

#: ../../source/models/model_abilities/image.rst:32
msgid "/v1/images/variations"
msgstr ""

#: ../../source/models/model_abilities/image.rst:35
msgid "Supported models"
msgstr "支持的模型列表"

#: ../../source/models/model_abilities/image.rst:37
msgid ""
"The Text-to-image API is supported with the following models in "
"Xinference:"
msgstr "Text-to-image API 在 Xinference 中支持以下模型："

#: ../../source/models/model_abilities/image.rst:39
msgid "sd-turbo"
msgstr ""

#: ../../source/models/model_abilities/image.rst:40
msgid "sdxl-turbo"
msgstr ""

#: ../../source/models/model_abilities/image.rst:41
msgid "stable-diffusion-v1.5"
msgstr ""

#: ../../source/models/model_abilities/image.rst:42
msgid "stable-diffusion-xl-base-1.0"
msgstr ""

#: ../../source/models/model_abilities/image.rst:43
#: ../../source/models/model_abilities/image.rst:146
msgid "sd3-medium"
msgstr ""

#: ../../source/models/model_abilities/image.rst:44
#: ../../source/models/model_abilities/image.rst:148
msgid "sd3.5-medium"
msgstr ""

#: ../../source/models/model_abilities/image.rst:45
#: ../../source/models/model_abilities/image.rst:150
msgid "sd3.5-large"
msgstr ""

#: ../../source/models/model_abilities/image.rst:46
#: ../../source/models/model_abilities/image.rst:144
msgid "FLUX.1-schnell"
msgstr ""

#: ../../source/models/model_abilities/image.rst:47
#: ../../source/models/model_abilities/image.rst:142
msgid "FLUX.1-dev"
msgstr ""

#: ../../source/models/model_abilities/image.rst:51
msgid "Quickstart"
msgstr "快速入门"

#: ../../source/models/model_abilities/image.rst:54
msgid "Text-to-image"
msgstr "文生图"

#: ../../source/models/model_abilities/image.rst:56
msgid ""
"The Text-to-image API mimics OpenAI's `create images API "
"<https://platform.openai.com/docs/api-reference/images/create>`_. We can "
"try Text-to-image API out either via cURL, OpenAI Client, or Xinference's"
" python client:"
msgstr ""
"可以通过 cURL、OpenAI Client 或 Xinference 的方式尝试使用 Text-to-image "
"API。"

#: ../../source/models/model_abilities/image.rst:111
msgid "Tips for Large Image Models including SD3-Medium, FLUX.1"
msgstr "大型图像模型部署（sd3-medium、FLUX.1 系列）贴士"

#: ../../source/models/model_abilities/image.rst:113
msgid "Useful extra parameters can be passed to launch including:"
msgstr "有用的传递给加载模型的额外参数包括："

#: ../../source/models/model_abilities/image.rst:115
msgid ""
"``--cpu_offload True``: specifying ``True`` will offload the components "
"of the model to CPU during inference in order to save memory, while "
"seeing a slight increase in inference latency. Model offloading will only"
" move a model component onto the GPU when it needs to be executed, while "
"keeping the remaining components on the CPU."
msgstr ""
"``--cpu_offload True``：指定 ``True`` 会在推理过程中将模型的组件卸载到 "
"CPU 上以节省内存，这会导致推理延迟略有增加。模型卸载仅会在需要执行时将"
"模型组件移动到 GPU 上，同时保持其余组件在 CPU 上"

#: ../../source/models/model_abilities/image.rst:119
msgid ""
"``--quantize_text_encoder <text encoder layer>``: We leveraged the "
"``bitsandbytes`` library to load and quantize the T5-XXL text encoder to "
"8-bit precision. This allows you to keep using all text encoders while "
"only slightly impacting performance."
msgstr ""
"``--quantize_text_encoder <text encoder layer>``：我们利用 ``bitsandbytes"
"`` 库加载并量化 T5-XXL 文本编码器至8位精度。这使得你能够在仅轻微影响性能"
"的情况下继续使用全部文本编码器。"

#: ../../source/models/model_abilities/image.rst:122
msgid ""
"``--text_encoder_3 None``, for sd3-medium, removing the memory-intensive "
"4.7B parameter T5-XXL text encoder during inference can significantly "
"decrease the memory requirements with only a slight loss in performance."
msgstr ""
"``--text_encoder_3 None``，对于 sd3-medium，移除在推理过程中内存密集型的"
"47亿参数T5-XXL文本编码器可以显著降低内存需求，而仅造成性能上的轻微损失。"

#: ../../source/models/model_abilities/image.rst:125
msgid "``--transformer_nf4 True``: use nf4 for transformer quantization."
msgstr "``--transformer_nf4 True`` ：使用 nf4 量化 transformer。"

#: ../../source/models/model_abilities/image.rst:126
msgid ""
"``--quantize``: Only work for MLX on Mac, Flux.1-dev and Flux.1-schnell "
"will switch to MLX engine on Mac, and ``quantize`` can be used to "
"quantize the model."
msgstr ""
"``--quantize`` ：只对 Mac 上的 MLX 引擎生效，Flux.1-dev 和 Flux.1-schnell"
"会在 Mac 上使用 MLX 引擎计算，``quantize`` 可以用来量化模型。"

#: ../../source/models/model_abilities/image.rst:129
msgid ""
"For WebUI, Just add additional parameters, e.g. add key ``cpu_offload`` "
"and value ``True`` to enable cpu offloading."
msgstr ""
"对于 WebUI，只需要添加额外参数，比如，添加 key ``cpu_offload`` 以及值 ``True`` "
"来开启 CPU 卸载。"

#: ../../source/models/model_abilities/image.rst:135
msgid ""
"From v0.16.1, Xinference by default enabled quantization for large image "
"models like Flux.1 and SD3.5 series. Below list default options."
msgstr ""
"从 v0.16.1 开始，Xinference 默认对大图像模型如 Flux.1 和 SD3.5 系列开启"
"量化。如下列出了默认的选项。"

#: ../../source/models/model_abilities/image.rst:140
msgid "Model"
msgstr "模型"

#: ../../source/models/model_abilities/image.rst:140
msgid "quantize_text_encoder"
msgstr ""

#: ../../source/models/model_abilities/image.rst:140
msgid "quantize"
msgstr ""

#: ../../source/models/model_abilities/image.rst:140
msgid "transformer_nf4"
msgstr ""

#: ../../source/models/model_abilities/image.rst:142
#: ../../source/models/model_abilities/image.rst:144
msgid "text_encoder_2"
msgstr ""

#: ../../source/models/model_abilities/image.rst:142
#: ../../source/models/model_abilities/image.rst:144
#: ../../source/models/model_abilities/image.rst:150
msgid "True"
msgstr ""

#: ../../source/models/model_abilities/image.rst:142
#: ../../source/models/model_abilities/image.rst:144
#: ../../source/models/model_abilities/image.rst:146
#: ../../source/models/model_abilities/image.rst:148
msgid "False"
msgstr ""

#: ../../source/models/model_abilities/image.rst:146
#: ../../source/models/model_abilities/image.rst:148
#: ../../source/models/model_abilities/image.rst:150
msgid "text_encoder_3"
msgstr ""

#: ../../source/models/model_abilities/image.rst:146
#: ../../source/models/model_abilities/image.rst:148
#: ../../source/models/model_abilities/image.rst:150
msgid "N/A"
msgstr ""

#: ../../source/models/model_abilities/image.rst:153
msgid ""
"If you want to disable some quantization, just set the corresponding "
"option to False. e.g. for Web UI, set key ``quantize_text_encoder`` and "
"value ``False`` and for command line, specify ``--quantize_text_encoder "
"False`` to disable quantization for text encoder."
msgstr ""
"如果你想关闭某些量化，只需要设置相应的选项为 False。比如，对于 Web UI，"
"设置 key ``quantize_text_encoder`` 和值 ``False``，"
"或对于命令行，指定 ``--quantize_text_encoder False`` 来关闭 text encoder 的量化。"

#: ../../source/models/model_abilities/image.rst:160
msgid "Image-to-image"
msgstr "图生图"

#: ../../source/models/model_abilities/image.rst:162
msgid "You can find more examples of Images API in the tutorial notebook:"
msgstr "你可以在教程笔记本中找到更多 Images API 的示例。"

#: ../../source/models/model_abilities/image.rst:166
msgid "Stable Diffusion ControlNet"
msgstr ""

#: ../../source/models/model_abilities/image.rst:169
msgid "Learn from a Stable Diffusion ControlNet example"
msgstr "学习一个 Stable Diffusion 控制网络的示例"

#: ../../source/models/model_abilities/image.rst:172
msgid "OCR"
msgstr ""

#: ../../source/models/model_abilities/image.rst:174
msgid "The OCR API accepts image bytes and returns the OCR text."
msgstr "OCR API 接受图像字节并返回 OCR 文本。"

#: ../../source/models/model_abilities/image.rst:176
msgid "We can try OCR API out either via cURL, or Xinference's python client:"
msgstr "可以通过 cURL 或 Xinference 的 Python 客户端来尝试 OCR API。"

#~ msgid ""
#~ "If you are trying to run large "
#~ "image models liek sd3-medium or FLUX.1"
#~ " series on GPU card that has "
#~ "less memory than 24GB, you may "
#~ "encounter OOM when launching or "
#~ "inference. Try below solutions."
#~ msgstr ""
#~ "如果你试图在显存小于24GB的GPU上运行像"
#~ "sd3-medium或FLUX.1系列这样的大型图像模型"
#~ "，你在启动或推理过程中可能会遇到显存"
#~ "溢出（OOM）的问题。尝试以下解决方案。"

#~ msgid "For FLUX.1 series, try to apply quantization."
#~ msgstr "对于 FLUX.1 系列，尝试应用量化。"

#~ msgid "For sd3-medium, apply quantization to ``text_encoder_3``."
#~ msgstr "对于 sd3-medium 模型，对 ``text_encoder_3`` 应用量化。"

#~ msgid "Or removing memory-intensive T5-XXL text encoder for sd3-medium."
#~ msgstr "或者，移除 sd3-medium 模型中内存密集型的 T5-XXL 文本编码器。"

