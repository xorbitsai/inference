# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Xorbits Inc.
# This file is distributed under the same license as the Xinference package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Xinference \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-09-04 15:18+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/user_guide/client_api.rst:5
msgid "Client API"
msgstr "客户端 API"

#: ../../source/user_guide/client_api.rst:7
msgid "Complete Client API Reference: :ref:`reference_index`"
msgstr "完整地 API 指南： :ref:`reference_index`"

#: ../../source/user_guide/client_api.rst:9
msgid ""
"To utilize the Client API, initiate the xinference server using the "
"command below:"
msgstr "使用 Client API，需要先使用以下命令拉起 Xinference 服务："

#: ../../source/user_guide/client_api.rst:18
msgid ""
"Based on the log above, the endpoint is `http://127.0.0.1:9997`. Users "
"can connect to the xinference server through this endpoint using the "
"Client."
msgstr ""
"在命令日志里会打印服务地址，上述日志中为 `http://127.0.0.1:9997`。用户可以通过 Client 连接 Xinference "
"服务。"

#: ../../source/user_guide/client_api.rst:20
msgid ""
"Models are categorized into LLM, embedding, image, etc. We plan to "
"introduce more model types in the future."
msgstr "所有模型被分为 LLM、embedding、rerank 等类型。后续可能会支持更多类型的模型。"

#: ../../source/user_guide/client_api.rst:23
msgid "LLM"
msgstr "LLM"

#: ../../source/user_guide/client_api.rst:25
msgid "To list the available built-in LLM models:"
msgstr "列出所有内置支持的 LLM 模型："

#: ../../source/user_guide/client_api.rst:38
msgid "To initialize an LLM and chat:"
msgstr "初始化一个大语言模型并且与之对话："

#: ../../source/user_guide/client_api.rst:41
#: ../../source/user_guide/client_api.rst:181
#: ../../source/user_guide/client_api.rst:252
#: ../../source/user_guide/client_api.rst:321
msgid "Xinference Client"
msgstr "Xinference Client"

#: ../../source/user_guide/client_api.rst:65
#: ../../source/user_guide/client_api.rst:213
#: ../../source/user_guide/client_api.rst:276
#: ../../source/user_guide/client_api.rst:345
msgid "OpenAI Client"
msgstr "OpenAI Client"

#: ../../source/user_guide/client_api.rst:67
msgid ""
"Openai client request with the same function as before, excluding launch "
"model. More details refer to: https://platform.openai.com/docs/api-"
"reference/chat?lang=python"
msgstr ""
"使用 Openai 发送请求时，除了创建模型，其余的请求都保持与 Openai 的接口兼容。Openai 使用方式可以参考 "
"https://platform.openai.com/docs/api-reference/chat?lang=python"

#: ../../source/user_guide/client_api.rst:89
msgid "OpenAI Client Tool Calls"
msgstr "OpenAI 工具调用"

#: ../../source/user_guide/client_api.rst:134
#: ../../source/user_guide/client_api.rst:195
#: ../../source/user_guide/client_api.rst:227
#: ../../source/user_guide/client_api.rst:267
#: ../../source/user_guide/client_api.rst:291
#: ../../source/user_guide/client_api.rst:335
#: ../../source/user_guide/client_api.rst:360
#: ../../source/user_guide/client_api.rst:389
msgid "Output:"
msgstr "输出："

#: ../../source/user_guide/client_api.rst:142
#, fuzzy
msgid "Anthropic Client"
msgstr "Anthropic Client"

#: ../../source/user_guide/client_api.rst:163
msgid "Embedding"
msgstr "Embedding"

#: ../../source/user_guide/client_api.rst:165
msgid "To list the available built-in embedding models:"
msgstr "列出所有内置支持的 embedding 模型："

#: ../../source/user_guide/client_api.rst:178
msgid "To launch an embedding model and embed text:"
msgstr "拉起 embedding 模型并使用文本向量化："

#: ../../source/user_guide/client_api.rst:215
msgid ""
"Openai client request with the same function as before, excluding launch "
"model. More details refer to: https://platform.openai.com/docs/api-"
"reference/embeddings?lang=python"
msgstr ""
"使用 Openai 发送请求时，除了创建模型，其余的请求都保持与 Openai 的接口兼容。Openai 使用方式可以参考 "
"https://platform.openai.com/docs/api-reference/embeddings?lang=python"

#: ../../source/user_guide/client_api.rst:234
msgid "Image"
msgstr "图片"

#: ../../source/user_guide/client_api.rst:236
#: ../../source/user_guide/client_api.rst:301
msgid "To list the available built-in image models:"
msgstr "列出所有内置的文生图模型："

#: ../../source/user_guide/client_api.rst:249
msgid "To initiate an image model and generate an image using a text prompt:"
msgstr "初始化一个文生图模型并通过提示词生成图片："

#: ../../source/user_guide/client_api.rst:278
msgid ""
"Openai client request with the same function as before, excluding launch "
"model. More details refer to: https://platform.openai.com/docs/api-"
"reference/images/create?lang=python"
msgstr ""
"使用 Openai 发送请求时，除了创建模型，其余的请求都保持与 Openai 的接口兼容。Openai 使用方式可以参考 "
"https://platform.openai.com/docs/api-reference/images/create?lang=python"

#: ../../source/user_guide/client_api.rst:299
msgid "Audio"
msgstr ""

#: ../../source/user_guide/client_api.rst:318
msgid "To initiate an audio model and get text from an audio:"
msgstr "初始化一个语音模型并通过语音生成文字："

#: ../../source/user_guide/client_api.rst:347
msgid ""
"Openai client request with the same function as before. More details "
"refer to: https://platform.openai.com/docs/api-"
"reference/audio/createTranscription"
msgstr ""
"使用 Openai 发送请求时，除了创建模型，其余的请求都保持与 Openai 的接口兼容。Openai 使用方式可以参考 "
"https://platform.openai.com/docs/api-reference/images/create?lang=python"

#: ../../source/user_guide/client_api.rst:368
msgid "Rerank"
msgstr "Rerank"

#: ../../source/user_guide/client_api.rst:369
msgid "To launch a rerank model and compute the similarity scores:"
msgstr "拉起 rerank 模型并计算文本相似度："

#~ msgid ""
#~ "Anthropic client request with the same"
#~ " function as before, excluding launch "
#~ "model."
#~ msgstr "使用 Anthropic 发送请求时，除了创建模型，其余的请求都保持与 Anthropic 的接口兼容。"

